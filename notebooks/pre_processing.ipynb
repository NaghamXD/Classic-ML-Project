{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from typing import Tuple, Union, Optional\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "# for ML models:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bokeh.plotting import figure, show, save, output_file\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.models.widgets import PreText\n",
    "from bokeh.models import BooleanFilter, ColumnDataSource, IndexFilter, BoxAnnotation, Band, Span, Select, LinearAxis, DataRange1d, Range1d\n",
    "from bokeh.models.formatters import PrintfTickFormatter, NumeralTickFormatter\n",
    "from bokeh.layouts import column\n",
    "from bokeh.io import output_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Enabling Plotly offline\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Financial Data\n",
    "import yfinance as yf\n",
    "import quantstats as qs\n",
    "import ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH_PLOT = 1500\n",
    "\n",
    "RED = Category20[7][6]\n",
    "GREEN = Category20[5][4]\n",
    "\n",
    "BLUE = Category20[3][0]\n",
    "BLUE_LIGHT = Category20[3][1]\n",
    "\n",
    "ORANGE = Category20[3][2]\n",
    "PURPLE = Category20[9][8]\n",
    "BROWN = Category20[11][10]\n",
    "\n",
    "# TOOLS = 'pan,wheel_zoom,reset'\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was extracted from yfinance, we chose IVV ticker for S&P 500 ETF, since its investable.\\\n",
    "the yfinance data inclused the Adjusted return column: a calculation adjustment made to a stock’s closing price.\\\n",
    "The original closing price does not exemplify the most accurate valuation of the stock or security since it will not account for any actions that could’ve caused the price to shift. Therefore, an adjusted closing price will include any adjustments that need to be made to the price\\\n",
    "The adjustments made are to compensate for anything that could’ve affected the stock’s value, such as a corporate action. The corporate actions can include dividends or stock splits. The adjustment made to the closing price will display the true price of the stock or security because certain outside factors could’ve altered the true price.\\\n",
    "LOG-RETURN: https://medium.datadriveninvestor.com/why-we-use-log-returns-for-stock-returns-820cec4510ba \\\n",
    "log returns are the preferred way to model stock returns, as proven in this article\n",
    "\n",
    "The use of the 'Adj Close' column instead of the 'Close' column to plot the chart above is due to the adjustment of historical prices for dividends and stock splits. The 'Adj Close' value represents the closing price adjusted for these factors, which allows for a more accurate representation of the stock's true price over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticker symbol for iShares Core S&P 500 ETF (IVV)\n",
    "ticker_symbol = \"IVV\"\n",
    "\n",
    "# Extracting data\n",
    "ivv_data = yf.download(ticker_symbol, start=\"2002-01-01\", end=\"2024-01-01\", interval=\"1d\")\n",
    "# https://corporatefinanceinstitute.com/resources/equities/adjusted-closing-price/\n",
    "ivv_data['Return'] = np.log(ivv_data['Adj Close']/ivv_data['Adj Close'].shift(1)).dropna()\n",
    "# Displaying the first few rows of the data\n",
    "print(ivv_data.head())\n",
    "ivv_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivv_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = qs.utils.download_returns(\"IVV\")\n",
    "sp500 = sp.loc['2002-01-01':'2024-01-01']\n",
    "sp500.index = sp500.index.tz_localize('UTC')\n",
    "benchmark = qs.utils.download_returns(\"21Y-Treasury\")\n",
    "\n",
    "print('\\nsp500 Daily Returns Plot:\\n')\n",
    "qs.plots.daily_returns(sp500, benchmark=benchmark)\n",
    "\n",
    "# Plotting Cumulative Returns for each stock\n",
    "print('\\n')\n",
    "print('\\nsp500 Cumulative Returns Plot\\n')\n",
    "qs.plots.returns(sp500)\n",
    "\n",
    "# Plotting histograms for daily returns \n",
    "print('\\n')\n",
    "print('\\nsp500 Inc. Daily Returns Histogram')\n",
    "qs.plots.histogram(sp500, resample = 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skewness - Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using quantstats to measure kurtosis\n",
    "print(\"SP500 kurtosis: \", qs.stats.kurtosis(sp500).round(2))\n",
    "# Measuring skewness with quantstats\n",
    "print('\\n')\n",
    "print(\"SP500 skewness: \", qs.stats.skew(sp500).round(2))\n",
    "# Calculating Standard Deviations\n",
    "print('\\n')\n",
    "print(\"SP500 Standard Deviation from 2002 to 2023: \", sp500.std().round(3))\n",
    "# Calculating Sharpe ratio\n",
    "print('\\n')\n",
    "print(\"Sharpe Ratio for SP500: \", qs.stats.sharpe(sp500).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stocks are subject to high levels of volatility and risk, with considerate price fluctuations that deviate significantly from their average returns.\n",
    "a value between -0.5 and 0.5 indicates a slight level of skewness, forn std it shows that sp500 is safer investment options, exhibiting more stable price fluctuations in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chach for imbalance in the return: if Skewness is high?\n",
    "log_returns = ivv_data['Return']\n",
    "\n",
    "\n",
    "# Plot histogram of log discrete returns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(log_returns, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Log Returns')\n",
    "plt.xlabel('Log Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a vertical line indicating the mean of log discrete returns\n",
    "mean_log_return = log_returns.mean()\n",
    "plt.axvline(mean_log_return, color='red', linestyle='dashed', linewidth=1, label='Mean Log Return')\n",
    "median_log_return = log_returns.median()\n",
    "plt.axvline(median_log_return, color='green', linestyle='dashed', linewidth=1, label='Median Log Return')\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price and Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting candlestick chart without indicators\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.05, row_heights = [0.7, 0.3])\n",
    "fig.add_trace(go.Candlestick(x=ivv_data.index,\n",
    "                             open=ivv_data['Open'],\n",
    "                             high=ivv_data['High'],\n",
    "                             low=ivv_data['Low'],\n",
    "                             close=ivv_data['Adj Close'],\n",
    "                             name='SP500'),\n",
    "              row=1, col=1)\n",
    "\n",
    "\n",
    "# Plotting volume chart on the second row \n",
    "fig.add_trace(go.Bar(x=ivv_data.index,\n",
    "                     y=ivv_data['Volume'],\n",
    "                     name='Volume',\n",
    "                     marker=dict(color='orange', opacity=1.0)),\n",
    "              row=2, col=1)\n",
    "\n",
    "# Plotting annotation\n",
    "fig.add_annotation(text='SP500',\n",
    "                    font=dict(color='black', size=40),\n",
    "                    xref='paper', yref='paper',\n",
    "                    x=0.5, y=0.65,\n",
    "                    showarrow=False,\n",
    "                    opacity=0.2)\n",
    "\n",
    "# Configuring layout\n",
    "fig.update_layout(title='SP500 Candlestick Chart From Jan 1st, 2002 to December 30th, 2023',\n",
    "                  yaxis=dict(title='Price (USD)'),\n",
    "                  height=1000)\n",
    "\n",
    "# Configuring axes and subplots\n",
    "fig.update_xaxes(rangeslider_visible=False, row=1, col=1)\n",
    "fig.update_xaxes(rangeslider_visible=False, row=2, col=1)\n",
    "fig.update_yaxes(title_text='Price (USD)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Volume', row=2, col=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomalies Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "def detect_anomalies(df, column):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # calculate Z-scores and add them as a new column\n",
    "    df_copy['Z-score'] = zscore(df_copy[column])\n",
    "\n",
    "    # find where the absolute Z-score is greater than 2 (common threshold for anomalies)\n",
    "    anomalies = df_copy[abs(df_copy['Z-score']) > 2]\n",
    "    return anomalies\n",
    "\n",
    "anomalies_adj_close = pd.DataFrame()\n",
    "anomalies_volume = pd.DataFrame()\n",
    "\n",
    "# for ticker in stock_data['Ticker'].unique():\n",
    "#     data_ticker = stock_data[stock_data['Ticker'] == ticker]\n",
    "\n",
    "#     adj_close_anomalies = detect_anomalies(data_ticker, 'Adj Close')\n",
    "#     volume_anomalies = detect_anomalies(data_ticker, 'Volume')\n",
    "\n",
    "#     # use concat instead of append\n",
    "#     anomalies_adj_close = pd.concat([anomalies_adj_close, adj_close_anomalies])\n",
    "#     anomalies_volume = pd.concat([anomalies_volume, volume_anomalies])\n",
    "adj_close_anomalies = detect_anomalies(ivv_data, 'Adj Close')\n",
    "volume_anomalies = detect_anomalies(ivv_data, 'Volume')\n",
    "\n",
    "# use concat instead of append\n",
    "anomalies_adj_close = pd.concat([anomalies_adj_close, adj_close_anomalies])\n",
    "anomalies_volume = pd.concat([anomalies_volume, volume_anomalies])\n",
    "\n",
    "print(anomalies_adj_close.head())\n",
    "\n",
    "def plot_anomalies(data_ticker, anomalies_adj_close, anomalies_volume):\n",
    "    # Filter the main and anomalies data for the given ticker\n",
    "    # data_ticker = stock_data[stock_data['Ticker'] == ticker]\n",
    "    # adj_close_anomalies = anomalies_adj_close[anomalies_adj_close['Ticker'] == ticker]\n",
    "    # volume_anomalies = anomalies_volume[anomalies_volume['Ticker'] == ticker]\n",
    "\n",
    "    # plotting\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "    # adjusted close price\n",
    "    ax1.plot(data_ticker.index, data_ticker['Adj Close'], label='Adj Close', color='blue')\n",
    "    ax1.scatter(anomalies_adj_close.index, anomalies_adj_close['Adj Close'], color='red', label='Anomalies')\n",
    "    ax1.set_title(f'SP500 Adjusted Close Price and Anomalies')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Adjusted Close Price')\n",
    "    ax1.legend()\n",
    "\n",
    "    # volume\n",
    "    ax2.plot(data_ticker.index, data_ticker['Volume'], label='Volume', color='green')\n",
    "    ax2.scatter(anomalies_volume.index, anomalies_volume['Volume'], color='orange', label='Anomalies')\n",
    "    ax2.set_title(f'SP500 Trading Volume and Anomalies')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Volume')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot anomalies for each ticker\n",
    "# for ticker in stock_data['Ticker'].unique():\n",
    "plot_anomalies(ivv_data, anomalies_adj_close, anomalies_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical analysis is a very popular method used for many traders and investors to evaluate stocks and other assets based on historical price and volume data. It is an approach used to identify trends, or lack of trends, and help traders and investors to make decisions based on what they believe the future price movements will be. The underlying assumption of technical analysis is that past patterns and price movements tend to repeat themselves, so those can be used to predict future movements. Therefore, technical analysts examine charts and look for opportunities in patterns and indicators.\n",
    "Despite its popularity among traders, the use of technical analysis may be controversial. Some critics argue that technical analysis relies too heavily on subjective interpretations of chart patterns and that it lacks a clear theoretical foundation. They also argue that technical analysis is prone to false signals and that traders who rely on technical analysis may miss out on important fundamental factors that can influence the price of stocks.\n",
    "It can be said that technical analysis tend to be more appropriate for short-term trading, whereas fundamental analysis may be better suited for long-term investing. Fundamental analysis provides investors with a more comprehensive understanding of a company's financial health and long-term growth prospects.\n",
    "It can also be said that, while humans tend to operate better with fundamental analysis, as it requires a deep understanding of the underlying factors that drive a company's value, computers may operate better with technical analysis, as it relies heavily on quantitative data that can be analyzed quickly and efficiently. An evidence to that is the fact that the use of automated trading bots that trade based on technical analysis has become increasingly popular in recent years. These bots use algorithms to identify patterns and trends in price data and make trades based on technical signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accumulation/distribution indicator (A/D) is a cumulative indicator that uses volume and price to assess whether a stock is being accumulated or distributed. The A/D measure seeks to identify divergences between the stock price and the volume flow. This provides insight into how strong a trend is. If the price is rising but the indicator is falling, then it suggests that buying or accumulation volume may not be enough to support the price rise and a price decline could be forthcoming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accumulation_distribution_indicator(close_prices: np.ndarray, high_prices: np.ndarray, low_prices: np.ndarray, volume: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Accumulation/Distribution Indicator (ADL or ADO) for a given security.\n",
    "\n",
    "    Parameters:\n",
    "    - high: High prices series (list, numpy array, or pandas Series)\n",
    "    - low: Low prices series (list, numpy array, or pandas Series)\n",
    "    - close: Close prices series (list, numpy array, or pandas Series)\n",
    "    - volume: Volume series (list, numpy array, or pandas Series)\n",
    "\n",
    "    Returns:\n",
    "    - adl: Accumulation/Distribution Indicator series (pandas Series)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate money flow multiplier\n",
    "    money_flow_multiplier = ((close_prices - low_prices) - (high_prices - close_prices)) / (high_prices - low_prices)\n",
    "\n",
    "    # Calculate money flow volume\n",
    "    money_flow_volume = money_flow_multiplier * volume\n",
    "\n",
    "    # Calculate Accumulation/Distribution Line\n",
    "    adl = money_flow_volume.cumsum()\n",
    "\n",
    "    return adl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volatility Indicators:/\n",
    "Volatility can be measured in a number of ways, including VIX, ATR, and Bollinger Bands to determine optimal exit or entry points for trades. While high volatility is often a deterrent for a risky trade, increased fear during extreme market moves and larger price swings can also create buying opportunities and provide an exceptional trading ground for experienced investors./\n",
    "\n",
    "Daily variation: a measure of volatility, or how much a stock's value changes.It is the difference between its highest and lowest values on a given trading day. A stock with a very large daily price variation is very volatile and may be expected to change its value quickly over time. When daily price variations are small, it indicates more consensus within the market about the value of the stock. Stable daily price variations over time show that a stock is unlikely to shoot up or plummet in value on any given day./\n",
    "\n",
    "Average True Range (ATR) is the average of true ranges over the specified period. ATR measures volatility, taking into account any gaps in the price movement. Typically, the ATR calculation is based on 14 periods, which can be intraday, daily, weekly, or monthly. ATR is very useful for stops or entry triggers, signaling changes in volatility. Whereas fixed dollar- point or percentage stops will not allow for volatility, the ATR stop will adapt to sharp price moves or consolidation areas, which can trigger an abnormal price movement in either direction./\n",
    "\n",
    "The Bollinger Bands consist of three lines on a chart: a simple moving average (SMA) in the middle,typically a 20-day moving average, and two bands that are set at a distance of two standard deviations away from the SMA. When the market is volatile, the bands widen, and when the market is less volatile, the bands contract. The distance between the bands can therefore be used as an indicator of volatility.It is designed to give investors a higher probability of identifying when an asset is oversold or overbought. Three lines compose Bollinger Bands: A simple moving average, or the middle band, and an upper and lower band. Many traders believe the closer the prices move to the upper band, the more overbought the market, and the closer the prices move to the lower band, the more oversold the market./\n",
    "\n",
    "Overbought --> Sell\n",
    "Oversold --> Buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility Indicators\n",
    "\n",
    "# Average True Range (ATR)\n",
    "def calculate_atr(open_prices: np.ndarray, high_prices: np.ndarray, low_prices: np.ndarray, window: int) -> np.ndarray:\n",
    "    daily_variation = (high_prices - low_prices) / open_prices\n",
    "    return daily_variation.rolling(window=window).mean()\n",
    "\n",
    "# Bollinger Band\n",
    "def calculate_bollinger_bands(close_prices: np.ndarray, window: int, num_std=2):\n",
    "    \"\"\"\n",
    "    Calculate the Bollinger Bands for a given set of closing prices.\n",
    "\n",
    "    Parameters:\n",
    "    - close_prices: List or array of closing prices\n",
    "    - window: Size of the moving average window (default is 20)\n",
    "    - num_std: Number of standard deviations for the bands (default is 2)\n",
    "\n",
    "    Returns:\n",
    "    - bollinger_upper: List of upper Bollinger Band values\n",
    "    - bollinger_lower: List of lower Bollinger Band values\n",
    "    \"\"\"\n",
    "    close_series = pd.Series(close_prices)\n",
    "    sma = close_series.rolling(window=window).mean()\n",
    "    rolling_std = close_series.rolling(window=window).std()\n",
    "\n",
    "    bollinger_upper = sma + (rolling_std * num_std)\n",
    "    bollinger_lower = sma - (rolling_std * num_std)\n",
    "\n",
    "    return round(bollinger_upper,2), round(sma, 2), round(bollinger_lower,2)\n",
    "\n",
    "# Bollinger Band Width\n",
    "def calculate_bollinger_width(bollinger_upper: np.ndarray, sma: np.ndarray, bollinger_lower: np.ndarray) -> np.ndarray:\n",
    "    return (bollinger_upper - bollinger_lower) / sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main chart for stock prices with candlestick and Bolinger bands\n",
    "def plot_stock_price(stock):\n",
    "    p = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=400,\n",
    "               title=\"Stock price + Bollinger Bands (2 std)\",\n",
    "               tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    inc_data = stock[stock['Close'] > stock['Open']]\n",
    "    dec_data = stock[stock['Open'] > stock['Close']]\n",
    "\n",
    "    width = 35000000\n",
    "\n",
    "    p.segment(x0='Date', x1='Date', y0='Low', y1='High', color=RED, source=inc_data)\n",
    "    p.segment(x0='Date', x1='Date', y0='Low', y1='High', color=GREEN, source=dec_data)\n",
    "\n",
    "    p.vbar(x='Date', width=width, top='Open', bottom='Close', fill_color=RED, line_color=RED,\n",
    "           source=inc_data)\n",
    "    p.vbar(x='Date', width=width, top='Open', bottom='Close', fill_color=GREEN, line_color=GREEN,\n",
    "           source=dec_data)\n",
    "\n",
    "    # Plot Simple Moving Average\n",
    "    p.line(x='Date', y='sma', line_width=2, color=BLUE, line_alpha=0.7,source=stock)\n",
    "    \n",
    "    # Creating vertices for the cloud-like shape between Bollinger Bands\n",
    "    cloud_x = list(stock['Date']) + list(stock['Date'][::-1])\n",
    "    cloud_y = list(stock['bolling_upper']) + list(stock['bolling_lower'][::-1])\n",
    "\n",
    "    cloud_source = ColumnDataSource(data=dict(x=cloud_x, y=cloud_y))\n",
    "\n",
    "    # Creating the patch for the cloud-like shape\n",
    "    p.patch('x', 'y', color=BLUE_LIGHT, line_color='black', alpha=0.3, source=cloud_source)\n",
    "    \n",
    "    # Sort by distances\n",
    "    stock_sorted_upper = stock.sort_values(by='distance_upper', ascending=True)\n",
    "    stock_sorted_lower = stock.sort_values(by='distance_lower', ascending=True)\n",
    "\n",
    "    # Add pointers to top 5 overbought and oversold points\n",
    "    p.triangle(x=stock_sorted_upper.iloc[:5]['Date'], y=stock_sorted_upper.iloc[:5]['Close'], size=10, color='darkorange', legend_label='Top 5 Overbought[best to sell]')\n",
    "    p.inverted_triangle(x=stock_sorted_lower.iloc[:5]['Date'], y=stock_sorted_lower.iloc[:5]['Close'], size=10, color='darkblue', legend_label='Top 5 Oversold[best to buy]')\n",
    "\n",
    "    # Set legend position\n",
    "    p.legend.location = \"top_left\"\n",
    "\n",
    "    code = \"\"\"\n",
    "    def ticker():\n",
    "        return \"{:.0f} + {:.2f}\".format(tick, tick % 1)\n",
    "    \"\"\"\n",
    "    p.yaxis.formatter = NumeralTickFormatter(format='$ 0,0[.]000')\n",
    "\n",
    "    return p\n",
    "\n",
    "def plot_bbw(stock):\n",
    "    # Create the sub-plot for Bollinger Band Width\n",
    "    p_sub = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=200,\n",
    "                   title=\"Bollinger Band Width\",\n",
    "                   tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    # Plot Bollinger Band Width\n",
    "    p_sub.line(x='Date', y='bbw', line_width=2, color='orange', source=stock)\n",
    "    \n",
    "    return p_sub\n",
    "\n",
    "def plot_atr(stock):\n",
    "    # Create the sub-plot for Bollinger Band Width\n",
    "    p_sub = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=200,\n",
    "                   title=\"Average True Range (ATR)\",\n",
    "                   tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    # Plot Bollinger Band Width\n",
    "    p_sub.line(x='Date', y='atr', line_width=2, color='purple', source=stock)\n",
    "    \n",
    "    return p_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Volatility:\n",
    "vis1_df = ivv_data.reset_index()\n",
    "vis1_df['bolling_upper'], vis1_df['sma'], vis1_df['bolling_lower'] = calculate_bollinger_bands(vis1_df['Close'], window=15)\n",
    "vis1_df['distance_upper'] = vis1_df['bolling_upper'] - vis1_df['Close']\n",
    "vis1_df['distance_lower'] = vis1_df['Close'] - vis1_df['bolling_lower']\n",
    "vis1_df['bbw'] = calculate_bollinger_width(vis1_df['bolling_upper'], vis1_df['sma'], vis1_df['bolling_lower'])\n",
    "vis1_df['atr'] = calculate_atr(vis1_df['Open'], vis1_df['High'], vis1_df['Low'], window=14)\n",
    "\n",
    "p = plot_stock_price(vis1_df.dropna())\n",
    "p_sub = plot_bbw(vis1_df.dropna())\n",
    "p_sub2 = plot_atr(vis1_df.dropna())\n",
    "\n",
    "# Combine the plots\n",
    "# output_notebook()\n",
    "plot_combined = column(p, p_sub, p_sub2)\n",
    "show(plot_combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving Averages:\\\n",
    "There are two types of moving averages: simple moving averages (SMA) and exponential moving averages (EMA). SMA calculates the average price of the asset over the specified period of time and gives equal weight to each data point.So, for instance, a 20-day SMA would take the sum of the closing prices over the past 20 days and divide by 20 to get the average price.\n",
    "EMA, on the other hand, gives more weight to recent price action. The formula for calculating EMA involves using a multiplier that gives more weight to the most recent price data.\n",
    "When a shorter-term EMA line crosses above a longer-term EMA line, it may be considered a buy signal, while when a shorter-term EMA line crosses below a longer-term EMA line, it may be considered a sell signal.\\\n",
    "\n",
    "Moving Average Convergence Divergence(MACD): help identify price trends, measure trend momentum, and identify market entry points for buying or selling. Buy when the MACD line crosses above the signal line and sell when the MACD line crosses below the signal line. \n",
    "\n",
    "Directional Moving Index: The Directional Movement Index (DMI) assists in determining if a security is trending and attempts to measure the strength of the trend. The DMI disregards the direction of the security. It only attempts to determine if there is a trend and that trends strength.\\\n",
    "A buy signal is given when DMI+ crosses above DMI-. A sell signal is given when DMI- crosses above DMI+. The ADX and ADXR lines are then used to measure the strength of these signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Moving Average: to reduce lag in responsiveness to price movements.\n",
    "# calculate for 12, 15, 26\n",
    "def calculate_ema(close_prices: np.ndarray, window: int) -> np.ndarray:\n",
    "    return close_prices.ewm(span=window, adjust=False).mean()\n",
    "\n",
    " # Moving Average Convergence Divergence\n",
    "def calculate_macd(close_prices:np.ndarray, \n",
    "                   short_window: int, \n",
    "                   long_window: int, \n",
    "                   signal_window: int):\n",
    "    # Calculate short-term (fast) EMA\n",
    "    short_ema = close_prices.ewm(span=short_window, min_periods=1, adjust=False).mean()\n",
    "\n",
    "    # Calculate long-term (slow) EMA\n",
    "    long_ema = close_prices.ewm(span=long_window, min_periods=1, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD line\n",
    "    macd = short_ema - long_ema\n",
    "\n",
    "    # Calculate MACD signal line\n",
    "    macd_signal = macd.ewm(span=signal_window, min_periods=1, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD histogram\n",
    "    macd_histogram = macd - macd_signal\n",
    "\n",
    "    return macd_histogram, macd, macd_signal\n",
    "#macd_12_26 =  ema_12 - ema_26\n",
    "\n",
    "def calculate_dmi(high_prices:np.ndarray, low_prices:np.ndarray):\n",
    "    high_shifted = high_prices.shift(1)\n",
    "    low_shifted = low_prices.shift(1)\n",
    "    dm_plus = high_prices - high_shifted\n",
    "    dm_minus = low_shifted - low_prices\n",
    "    dm_plus[dm_plus < 0] = 0\n",
    "    dm_minus[dm_minus < 0] = 0\n",
    "    tr =  (high_prices - low_prices) \n",
    "    atr = tr.rolling(window=14).mean()\n",
    "    di_plus = (dm_plus / atr).rolling(window=14).mean() * 100\n",
    "    di_minus = (dm_minus / atr).rolling(window=14).mean() * 100\n",
    "    adx = np.abs(di_plus - di_minus) / (di_plus + di_minus) * 100 # Average Directional Movement Index\n",
    "    return di_plus, di_minus, adx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_averages(stock):\n",
    "    p = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=400,\n",
    "               title=\"Stock price\",\n",
    "               tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    inc_data = stock[stock['Close'] > stock['Open']]\n",
    "    dec_data = stock[stock['Open'] > stock['Close']]\n",
    "\n",
    "    width = 35000000\n",
    "\n",
    "    p.segment(x0='Date', x1='Date', y0='Low', y1='High', color=RED, source=inc_data)\n",
    "    p.segment(x0='Date', x1='Date', y0='Low', y1='High', color=GREEN, source=dec_data)\n",
    "\n",
    "    p.vbar(x='Date', width=width, top='Open', bottom='Close', fill_color=RED, line_color=RED,\n",
    "           source=inc_data)\n",
    "    p.vbar(x='Date', width=width, top='Open', bottom='Close', fill_color=GREEN, line_color=GREEN,\n",
    "           source=dec_data)\n",
    "\n",
    "    # Sort by distances\n",
    "    stock_sorted_upper = stock.sort_values(by='long_short', ascending=True)\n",
    "    stock_sorted_lower = stock.sort_values(by='short_long', ascending=True)\n",
    "\n",
    "    # Add pointers to top 5 overbought and oversold points\n",
    "    p.triangle(x=stock_sorted_upper.iloc[:5]['Date'], y=stock_sorted_upper.iloc[:5]['Close'], size=10, color='darkorange', legend_label='Top 5 periods to sell')\n",
    "    p.inverted_triangle(x=stock_sorted_lower.iloc[:5]['Date'], y=stock_sorted_lower.iloc[:5]['Close'], size=10, color='darkblue', legend_label='Top 5 periods to buy')\n",
    "\n",
    "    # Add legend\n",
    "    p.legend.location = \"top_left\"\n",
    "    \n",
    "    code = \"\"\"\n",
    "    def ticker():\n",
    "        return \"{:.0f} + {:.2f}\".format(tick, tick % 1)\n",
    "    \"\"\"\n",
    "    p.yaxis.formatter = NumeralTickFormatter(format='$ 0,0[.]000')\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "def plot_ema(stock):\n",
    "    # Create the sub-plot for Bollinger Band Width\n",
    "    p_sub = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=200,\n",
    "                   title=\"Exponential Moving Average(EMA)\",\n",
    "                   tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    # Plot Bollinger Band Width\n",
    "    p_sub.line(x='Date', y='ema_short', legend_label='ema short', line_width=2, color='gold', source=stock)\n",
    "    p_sub.line(x='Date', y='ema_long', legend_label='ema long',line_width=2, color='green', source=stock)\n",
    "    p_sub.legend.location = \"top_left\"\n",
    "    return p_sub\n",
    "\n",
    "# MACD (line + histogram)\n",
    "def plot_macd(stock):\n",
    "    p = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=300, title=\"MACD (line + histogram)\",\n",
    "               tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    up = stock[stock['macd_histogram'] > 0]\n",
    "    down = stock[stock['macd_histogram']<0]\n",
    "\n",
    "\n",
    "    p.vbar(x='Date', top='macd_histogram', bottom=0, width=30000000, color=GREEN, source=up, legend_label='MACD Histogram (Positive)')\n",
    "    p.vbar(x='Date', top=0, bottom='macd_histogram', width=30000000, color=RED, source=down,legend_label='MACD Histogram (Negative)')\n",
    "\n",
    "    # Adding an extra range for the MACD lines, because using the same axis as the histogram\n",
    "    # sometimes flattens them too much\n",
    "    p.extra_y_ranges = {'macd': DataRange1d()}\n",
    "    p.add_layout(LinearAxis(y_range_name='macd'), 'right')\n",
    "\n",
    "    p.line(x='Date', y='macd', line_width=2, color=BLUE, source=stock, legend_label='MACD', muted_color=BLUE,\n",
    "           muted_alpha=0, y_range_name='macd')\n",
    "    p.line(x='Date', y='macd_signal', line_width=2, color=BLUE_LIGHT, source=stock, legend_label='Signal',\n",
    "           muted_color=BLUE_LIGHT, muted_alpha=0, y_range_name='macd')\n",
    "\n",
    "    p.legend.location = \"bottom_left\"\n",
    "    p.legend.border_line_alpha = 0\n",
    "    p.legend.background_fill_alpha = 0\n",
    "    p.legend.click_policy = \"mute\"\n",
    "\n",
    "    p.yaxis.ticker = []\n",
    "    p.yaxis.axis_line_alpha = 0\n",
    "\n",
    "    return p\n",
    "\n",
    "def plot_dmi(stock):\n",
    "    # Create the sub-plot for Bollinger Band Width\n",
    "    p_sub = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=200,\n",
    "                   title=\"Directional Moving Index(DMI)\",\n",
    "                   tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    # Plot Bollinger Band Width\n",
    "    p_sub.line(x='Date', y='di_plus', legend_label='DI+',line_width=2, color='purple', source=stock)\n",
    "    p_sub.line(x='Date', y='di_minus',legend_label='DI-', line_width=2, color='orange', source=stock)\n",
    "    p_sub.line(x='Date', y='adx', legend_label='Average Directional Movement Index', line_width=1,alpha=0.3 ,color='blue', source=stock)\n",
    "    \n",
    "    p_sub.legend.location = \"top_left\"\n",
    "\n",
    "    return p_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize averages:\n",
    "vis1_df['ema_short'] = calculate_ema(vis1_df['Close'], window=12)\n",
    "vis1_df['ema_long'] = calculate_ema(vis1_df['Close'], window=26)\n",
    "vis1_df['short_long'] = vis1_df['ema_short'] - vis1_df['ema_long']\n",
    "vis1_df['long_short'] = vis1_df['ema_long'] -  vis1_df['ema_short']\n",
    "vis1_df['macd_histogram'], vis1_df['macd'], vis1_df['macd_signal'] = calculate_macd(vis1_df['Close'], short_window=12, long_window=26, signal_window=14)\n",
    "vis1_df['macd_above'] = vis1_df['macd'] - vis1_df['macd_signal']\n",
    "vis1_df['macd_under'] = vis1_df['macd_signal'] - vis1_df['macd']\n",
    "vis1_df['di_plus'], vis1_df['di_minus'], vis1_df['adx'] = calculate_dmi(vis1_df['High'], vis1_df['Low'])\n",
    "\n",
    "p2 =  plot_stock_averages(vis1_df.dropna())\n",
    "p2_sub = plot_ema(vis1_df.dropna())\n",
    "p2_sub2 = plot_macd(vis1_df.dropna())\n",
    "p2_sub3 = plot_dmi(vis1_df.dropna())\n",
    "\n",
    "plot2_combined = column(p2, p2_sub, p2_sub2, p2_sub3)\n",
    "\n",
    "show(plot2_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oscillators:\\\n",
    "\n",
    "Relative Strength Index (RSI): is a momentum indicator that measures recent price changes as it moves between 0 and 100. The RSI provides short-term buy and sell signals and is used to track the overbought and oversold levels of an asset.\n",
    "Low RSI levels, below 30, generate buy signals and indicate an oversold or undervalued condition. High RSI levels, above 70, generate sell signals and suggest that a security is overbought or overvalued.\n",
    "\n",
    "Williams %R: A trader might sell when the Williams %R indicator is above the overbought line (80) and then falls below the 80 line.\n",
    "Read more at: https://commodity.com/technical-analysis/williams-r/\n",
    "\n",
    "Fast stochastic indicator (%K) : is a momentum technical indicator that aims to measure the trend in prices and identify trend reversals. Typically, a stock is considered overbought if the %K is above 80 and oversold if %K is below 20. Buy signals are given when %K moves up through the %D line(%K below 20) . Sell signals are given when %K moves down through the %D line(%K above 80), It indicates a weakness in the uptrend and that the price may begin to fall. %D divergence is the 3-day SMA of the %K. It is a smoothed version of the %K. It is computed because %K is a volatile indicator and can lead to spurious signals. A smoothed version (%D) moves much slower than the %K; hence the signals generated indicate a stronger trend. When the stochastic oscillator falls below 20, the trader should look for two further conditions. First, the trader should check if the %K has fallen below %D, then see if there is a divergence in the movement of %K and the stock price. If the stock price has fallen further, but the %K rises, then it is a reversal in the trend. According to the stochastic oscillator analysis, it is a buy signal, and the trader should place a buy order. The stock is sold when the oscillator crosses 80, and a sell signal is generated. When the stochastic indicator rises above 80, it is the precondition to search for the bear divergence. A bear divergence occurs when the %K is above %D. Further, the stock price makes a high while the oscillator (%K) falls. It indicates a weakness in the uptrend and that the price may begin to fall. According to stochastic oscillator analysis, it is a sell signal, and the trader should place a sell order. The stock is repurchased when the next buy signal is generated. The fast stochastic indicator is much more volatile than the slow indicator. It generates many more buy and sell signals than the slow indicator( we will use fast %K, and fast %D)\n",
    "Read more at: https://corporatefinanceinstitute.com/resources/career-map/sell-side/capital-markets/fast-stochastic-indicator/#:~:text=A%20bear%20divergence%20occurs%20when,should%20place%20a%20sell%20order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oscillators\n",
    "\n",
    "# Stochastic Oscillator (STOCH) \n",
    "def calculate_stoch(close_prices: np.ndarray, \n",
    "                    low_prices: np.ndarray, \n",
    "                    high_prices: np.ndarray, \n",
    "                    n_fast_k=14, \n",
    "                    n_fast_d=3,\n",
    "                    n_slow_d=3):\n",
    "    # Calculate %K\n",
    "    L14 = low_prices.rolling(window=n_fast_k).min()\n",
    "    H14 = high_prices.rolling(window=n_fast_k).max()\n",
    "    K = 100 * (close_prices - L14) / (H14 - L14) \n",
    "    # Calculate %D [fast, slow]\n",
    "    D_Fast = K.rolling(window=n_fast_d).mean()  \n",
    "    D_Slow = D_Fast.rolling(window=n_slow_d).mean()\n",
    "    return K, D_Fast, D_Slow\n",
    "\n",
    "# Relative Strength Index\n",
    "# calculate for 14 days\n",
    "def calculate_rsi(close_prices: np.ndarray, window: int) -> np.ndarray:\n",
    "    delta = close_prices.diff()\n",
    "    delta = delta[1:] \n",
    "    up = delta.clip(lower=0)\n",
    "    down = -1*delta.clip(upper=0)\n",
    "    ema_up = up.ewm(com=window-1 , min_periods=window).mean()\n",
    "    ema_down = down.ewm(com=window-1 , min_periods=window).mean()\n",
    "    return 100 * ema_up/(ema_down + ema_up)\n",
    "\n",
    "# Williams %R: between 0 and -100 \n",
    "# calculate for 14 days \n",
    "def calculate_williams(close_prices: np.ndarray, \n",
    "                       low_prices: np.ndarray, \n",
    "                       high_prices: np.ndarray, \n",
    "                       window: int) -> np.ndarray:\n",
    "    highest_high = high_prices.rolling(window).max()\n",
    "    lowest_low = low_prices.rolling(window).min()\n",
    "    williams = ((highest_high - close_prices) / (highest_high - lowest_low)) * 100\n",
    "    \n",
    "    return williams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_osci(stock):\n",
    "    p = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=400,\n",
    "               title=\"Stock price\",\n",
    "               tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    inc_data = stock[stock['Close'] > stock['Open']]\n",
    "    dec_data = stock[stock['Open'] > stock['Close']]\n",
    "\n",
    "    width = 35000000\n",
    "\n",
    "    p.segment(x0='Date', x1='Date', y0='Low', y1='High', color=RED, source=inc_data)\n",
    "    p.segment(x0='Date', x1='Date', y0='Low', y1='High', color=GREEN, source=dec_data)\n",
    "\n",
    "    p.vbar(x='Date', width=width, top='Open', bottom='Close', fill_color=RED, line_color=RED,\n",
    "           source=inc_data)\n",
    "    p.vbar(x='Date', width=width, top='Open', bottom='Close', fill_color=GREEN, line_color=GREEN,\n",
    "           source=dec_data)\n",
    "\n",
    "    # Sort by distances\n",
    "    stock_sorted_under = stock.sort_values(by='macd_under', ascending=True)\n",
    "    stock_sorted_above = stock.sort_values(by='macd_above', ascending=True)\n",
    "\n",
    "    # Add pointers to top 5 overbought and oversold points\n",
    "    p.triangle(x=stock_sorted_under.iloc[:5]['Date'], y=stock_sorted_under.iloc[:5]['Close'], size=10, color='darkorange', legend_label='Top 5 periods to sell')\n",
    "    p.inverted_triangle(x=stock_sorted_above.iloc[:5]['Date'], y=stock_sorted_above.iloc[:5]['Close'], size=10, color='darkblue', legend_label='Top 5 periods to buy')\n",
    "\n",
    "    # Add legend\n",
    "    p.legend.location = \"top_left\"\n",
    "    \n",
    "    code = \"\"\"\n",
    "    def ticker():\n",
    "        return \"{:.0f} + {:.2f}\".format(tick, tick % 1)\n",
    "    \"\"\"\n",
    "    p.yaxis.formatter = NumeralTickFormatter(format='$ 0,0[.]000')\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RSI\n",
    "def plot_rsi(stock):\n",
    "    p = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=200, title=\"RSI 14 days\\nPink --> Buy | Green --> Sell\",\n",
    "               tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    p.line(x='Date', y='rsi', line_width=2, color=BLUE, source=stock)\n",
    "\n",
    "    low_box = BoxAnnotation(top=20, fill_alpha=0.1, fill_color=RED)\n",
    "    p.add_layout(low_box)\n",
    "    high_box = BoxAnnotation(bottom=80, fill_alpha=0.1, fill_color=GREEN)\n",
    "    p.add_layout(high_box)\n",
    "\n",
    "    # Horizontal line\n",
    "    hline = Span(location=50, dimension='width', line_color='black', line_width=0.5)\n",
    "    p.renderers.extend([hline])\n",
    "\n",
    "    p.y_range = Range1d(0, 100)\n",
    "    p.yaxis.ticker = [20, 50, 800]\n",
    "    p.yaxis.formatter = PrintfTickFormatter(format=\"%f%%\")\n",
    "    p.grid.grid_line_alpha = 0.2\n",
    "\n",
    "    return p\n",
    "\n",
    "# RSI\n",
    "def plot_williams(stock):\n",
    "    p = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=200, title=\"Williams %R 14 days\\nPink --> Buy | Green --> Sell\",\n",
    "               tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    p.line(x='Date', y='williams', line_width=2, color=BLUE, source=stock)\n",
    "\n",
    "    low_box = BoxAnnotation(top=20, fill_alpha=0.1, fill_color=RED)\n",
    "    p.add_layout(low_box)\n",
    "    high_box = BoxAnnotation(bottom=80, fill_alpha=0.1, fill_color=GREEN)\n",
    "    p.add_layout(high_box)\n",
    "\n",
    "    # Horizontal line\n",
    "    hline = Span(location=50, dimension='width', line_color='black', line_width=0.5)\n",
    "    p.renderers.extend([hline])\n",
    "\n",
    "    p.y_range = Range1d(0, 100)\n",
    "    p.yaxis.ticker = [20, 50, 800]\n",
    "    p.yaxis.formatter = PrintfTickFormatter(format=\"%f%%\")\n",
    "    p.grid.grid_line_alpha = 0.2\n",
    "\n",
    "    return p\n",
    "\n",
    "#  %K, %D\n",
    "def plot_k_d(stock):\n",
    "    p = figure(x_axis_type=\"datetime\", width=WIDTH_PLOT, height=200, title=\"%K - %D 14 days\\nPink --> Buy | Green --> Sell\",\n",
    "               tools=TOOLS, toolbar_location='above')\n",
    "\n",
    "    p.line(x='Date', y='k', line_width=2, color=BLUE, source=stock)\n",
    "    p.line(x='Date', y='d_fast', line_width=2, color=ORANGE,alpha=0.6, source=stock)\n",
    "\n",
    "\n",
    "    low_box = BoxAnnotation(top=20, fill_alpha=0.1, fill_color=RED)\n",
    "    p.add_layout(low_box)\n",
    "    high_box = BoxAnnotation(bottom=80, fill_alpha=0.1, fill_color=GREEN)\n",
    "    p.add_layout(high_box)\n",
    "\n",
    "    # Horizontal line\n",
    "    hline = Span(location=50, dimension='width', line_color='black', line_width=0.5)\n",
    "    p.renderers.extend([hline])\n",
    "\n",
    "    p.y_range = Range1d(0, 100)\n",
    "    p.yaxis.ticker = [20, 50, 800]\n",
    "    p.yaxis.formatter = PrintfTickFormatter(format=\"%f%%\")\n",
    "    p.grid.grid_line_alpha = 0.3\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize averages:\n",
    "vis1_df['rsi']= calculate_rsi(vis1_df['Close'], window=14)\n",
    "vis1_df['k'], vis1_df['d_fast'], _ = calculate_stoch(vis1_df['Close'], vis1_df['Low'], vis1_df['High'])\n",
    "vis1_df['williams']= calculate_williams(vis1_df['Close'],vis1_df['Low'], vis1_df['High'], window=14)\n",
    "\n",
    "p3 = plot_stock_osci(vis1_df.dropna())\n",
    "p3_sub = plot_williams(vis1_df.dropna())\n",
    "p3_sub2 = plot_rsi(vis1_df.dropna())\n",
    "p3_sub3 = plot_k_d(vis1_df.dropna())\n",
    "\n",
    "plot3_combined = column(p3, p3_sub, p3_sub2, p3_sub3)\n",
    "\n",
    "show(plot3_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target(Dependable) Variable : \n",
    "    Trading Signal [Buy, Sell] https://core.ac.uk/download/pdf/239040003.pdf\n",
    "\n",
    "\n",
    "y pred: is the the predicted return from a regression model\n",
    "\n",
    "Signal = \n",
    "\\begin{cases}\n",
    "1 & \\text{if}\\quad y_{\\text{pred}}(t) \\geq q_{0.6} \\\\\n",
    "0 & \\text{if}\\quad q_{0.4} < y_{\\text{pred}}(t) < q_{0.6} \\\\\n",
    "-1 & \\text{if}\\quad y_{\\text{pred}}(t) \\leq q_{0.4}\n",
    "\\end{cases}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_signals(y_pred: np.ndarray, q_low=0.4, q_high=0.6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate trading signals based on predicted values and quantiles.\n",
    "    signalt = {1  yt ≥ q0.6\n",
    "               0  q0.4 < yt < q0.6 \n",
    "               −1 yt ≤ q0.4}\n",
    "    Parameters:\n",
    "        y_pred (np.ndarray): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Trading signals.\n",
    "    \"\"\"\n",
    "    q_40 = np.quantile(y_pred, q_low)\n",
    "    q_60 = np.quantile(y_pred, q_high)\n",
    "    signals = np.zeros_like(y_pred)  # Initialize signals vector with zeros\n",
    "\n",
    "    # Calculate signals based on quantiles\n",
    "    signals[y_pred >= q_60] = 1  # Buy signal\n",
    "    signals[(y_pred > q_40) & (y_pred < q_60)] = 0  # Neutral signal\n",
    "    signals[y_pred <= q_40] = -1  # Sell signal\n",
    "\n",
    "    return signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Indicators Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df of indicators:\n",
    "df = pd.DataFrame(index=ivv_data.index)\n",
    "df['bolling_upper'], df['sma'], df['bolling_lower'] = calculate_bollinger_bands(ivv_data['Adj Close'], window=14)\n",
    "df['bbw'] = calculate_bollinger_width(df['bolling_upper'], df['sma'], df['bolling_lower'])\n",
    "\n",
    "df['ema'] = calculate_ema(ivv_data['Adj Close'], window=14)\n",
    "_, _, df['macd'] = calculate_macd(ivv_data['Adj Close'], short_window=12, long_window=26, signal_window=14)\n",
    "df['k'], _ , _ = calculate_stoch(ivv_data['Adj Close'], ivv_data['Low'], ivv_data['High'])\n",
    "df['rsi'] = calculate_rsi(ivv_data['Adj Close'], window=14)\n",
    "df['williams_r'] = calculate_williams(ivv_data['Adj Close'], ivv_data['Low'], ivv_data['High'], window=14)\n",
    "df['atr'] = calculate_atr(ivv_data['Open'], ivv_data['High'], ivv_data['Low'], window=14)\n",
    "_, _, df['adx'] = calculate_dmi(ivv_data['High'], ivv_data['Low'])\n",
    "df['adi'] = calculate_accumulation_distribution_indicator(ivv_data['Adj Close'], ivv_data['High'], ivv_data['Low'],ivv_data['Volume'])\n",
    "\n",
    "df['return'] = ivv_data['Return']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.iloc[:,:-1].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Features')\n",
    "ax.xaxis.tick_top()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization techniques:\\\n",
    "\n",
    "https://itadviser.dev/stock-market-data-normalization-for-time-series/#:~:text=Moving%20average%20normalization%20smoothens%20out,price%20by%20its%20moving%20average.\n",
    "\n",
    "Data transformation: min-max normalization (rescaled to range from -1 to 1):\n",
    "\n",
    "$x'_t = \\left(\\frac{x_t - \\min(x)}{\\max(x) - \\min(x)}\\right) \\times 2 - 1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale_df(df):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    scaled_data = scaler.fit_transform(df.values)\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=df.columns, index=df.index)\n",
    "    return scaled_df\n",
    "\n",
    "df = df.drop(['bolling_upper', 'bolling_lower', 'sma', 'bbw', 'adi', 'k'], axis=1)#, 'ema', 'sma'\n",
    "\n",
    "scaled_df = min_max_scale_df(df.iloc[:,:-1].dropna())#.iloc[:,:-1]\n",
    "scaled_df['return'] = df['return']\n",
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WFO : walk- forward optimization\\\n",
    "|X||V|O|O|O|\\\n",
    "|O|X||V|O|O|\\\n",
    "|O|O|X||V|O|\\\n",
    "|O|O|O|X||V|\n",
    "\n",
    "X = train\n",
    "\n",
    "V = validation  \n",
    "\n",
    "||=indicates a gap (parameter n_gap: int>0) truncated at the beginning of the validation set, in order to prevent leakage effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rolling_calendar(start_date, end_date, out_of_sample_size, runs, n_gap):\n",
    "    days = (end_date - start_date).days\n",
    "\n",
    "    in_sample_size = (100 - out_of_sample_size) / 100\n",
    "    out_of_sample_size = out_of_sample_size / 100\n",
    "\n",
    "    total_days_per_run = round(days / (runs * out_of_sample_size + in_sample_size))\n",
    "    in_sample_days_per_run = round(total_days_per_run * in_sample_size)\n",
    "    out_of_sample_days_per_run = round(total_days_per_run * out_of_sample_size)\n",
    "\n",
    "    calendar = pd.DataFrame()\n",
    "\n",
    "    calendar['InSampleStarts'] = [start_date + timedelta(days=(out_of_sample_days_per_run * x))\n",
    "                                  for x in range(runs)]\n",
    "    calendar['InSampleEnds'] = [x + timedelta(days=in_sample_days_per_run)\n",
    "                                for x in calendar['InSampleStarts']]\n",
    "\n",
    "    calendar['OutSampleStarts'] = [start_date + timedelta(days=in_sample_days_per_run + n_gap) +\n",
    "                                   timedelta(days=(out_of_sample_days_per_run * x))\n",
    "                                   for x in range(runs)]\n",
    "    calendar['OutSampleEnds'] = [x + timedelta(days=out_of_sample_days_per_run -1)\n",
    "                                 for x in calendar['OutSampleStarts']]\n",
    "\n",
    "\n",
    "    return calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = 10\n",
    "train = np.array(scaled_df[:])\n",
    "X, y = train[:, :-1], train[:, -1]\n",
    "calendar = build_rolling_calendar(start_date=scaled_df.index.min(), end_date=scaled_df.index.max(), out_of_sample_size=20, runs=10, n_gap=20)\n",
    "# end_date=scaled_df.index.max()\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for i, row in calendar.iterrows():\n",
    "    ax.plot([row['InSampleStarts'].year, row['InSampleEnds'].year], [i, i], color='blue')\n",
    "    ax.plot([row['OutSampleStarts'].year, row['OutSampleEnds'].year], [i, i], color='red')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_yticks(calendar.index.values[::-1])\n",
    "ax.set_yticklabels(calendar.index.values[::-1])\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Index')\n",
    "ax.set_title('Sample Periods')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN-TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "y_train = []\n",
    "y_valid = []\n",
    "for i, row in calendar.iterrows():\n",
    "    train = scaled_df.loc[row['InSampleStarts']: row['InSampleEnds']].to_numpy()\n",
    "    X_train.append(train[:, :-1])\n",
    "    y_train.append(train[:, -1])\n",
    "    valid = scaled_df.loc[row['OutSampleStarts']: row['OutSampleEnds']].to_numpy()\n",
    "    X_valid.append(valid[:, :-1])\n",
    "    y_valid.append(valid[:,-1])\n",
    "    if i == 0: \n",
    "        X_train_signals = scaled_df.loc[row['OutSampleStarts']:].to_numpy()\n",
    "\n",
    "\n",
    "flattened_y_valid = np.array(list(chain(*y_valid)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first xgboost feature importance:\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
    "    model.fit(X_train[i], y_train[i])\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': scaled_df.iloc[:, :-1].columns,\n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from XGBOOST', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
