{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, time, timedelta\n",
    "\n",
    "#for models\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "#for gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "#for Data\n",
    "import yfinance as yf\n",
    "\n",
    "#for Data Distribution\n",
    "from scipy import stats\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch historical data for the S&P 500\n",
    "sp500_data = yf.download('^GSPC', start='2002-01-01', end='2023-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_validation_set = yf.download('^GSPC', start='2023-01-02', end='2024-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing features:\n",
    "chosen_features = ['WMA', 'MACD', 'RSI', '%D_fast', '%D_slow', 'Bollinger Diff',\n",
    "                    'WPR', 'OBV', 'ROC', 'ATR', 'MFI', 'Chaikin_Oscillator', 'Adj Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the data\n",
    "nan_values_df = sp500_data.isna().any()\n",
    "\n",
    "print(\"NaN values in DataFrame:\")\n",
    "print(nan_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Moving Average:\n",
    "#returns the dataframe with additional coumn of simple moving average\n",
    "def calculate_sma(df: pd.DataFrame, column: str = 'Adj Close', window_size: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Simple Moving Average (SMA) for a given column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the financial data.\n",
    "        column (str): Name of the column for which to calculate SMA. Default is 'close'.\n",
    "        window_size (int): Size of the moving window. Default is 15.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with SMA column added.\n",
    "    \"\"\"\n",
    "    # Calculate SMA\n",
    "    sma = df[column].rolling(window=window_size, min_periods=1).mean()\n",
    "    \n",
    "    # Create a DataFrame to store SMA\n",
    "    df['SMA'] = sma\n",
    "    df['SMA_signal'] = df['Close'] - df['SMA']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weighted Moving Average\n",
    "def calculate_wma(df: pd.DataFrame, column: str = 'Adj Close', window_size: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Weighted Moving Average (WMA) for a given column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the financial data.\n",
    "        column (str): Name of the column for which to calculate WMA. Default is 'close'.\n",
    "        window_size (int): Size of the moving window. Default is 15.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with WMA and WMA signal columns added.\n",
    "    \"\"\"\n",
    "    # Generate the weights\n",
    "    weights = np.arange(1, window_size + 1)\n",
    "    data = df[column]\n",
    "    \n",
    "    # Calculate the WMA using convolution\n",
    "    wma = data.rolling(window=window_size).apply(lambda prices: np.dot(prices, weights) / weights.sum(), raw=True)\n",
    "    \n",
    "    # Create a DataFrame to store WMA\n",
    "    df['WMA'] = wma\n",
    "    \n",
    "    # Add WMA signal column\n",
    "    df['WMA_signal'] = df[column] - wma\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACD\n",
    "def calculate_macd(df: pd.DataFrame, short_window:int=12, long_window:int=26, signal_window:int=9, column: str = 'Adj Close') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the Moving Average Convergence Divergence (MACD) for a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        short_window (int): The short-term window size for the short EMA.\n",
    "        long_window (int): The long-term window size for the long EMA.\n",
    "        signal_window (int): The window size for the signal line EMA.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with additional columns for MACD and signal line.\n",
    "    \"\"\"\n",
    "    # Calculate short-term EMA\n",
    "    short_ema = df[column].ewm(span=short_window, min_periods=1, adjust=False).mean()\n",
    "    \n",
    "    # Calculate long-term EMA\n",
    "    long_ema = df[column].ewm(span=long_window, min_periods=1, adjust=False).mean()\n",
    "    \n",
    "    # Calculate MACD line\n",
    "    macd_line = short_ema - long_ema\n",
    "    \n",
    "    # Calculate signal line\n",
    "    signal_line = macd_line.ewm(span=signal_window, min_periods=1, adjust=False).mean()\n",
    "    \n",
    "    # Store MACD and signal line in the DataFrame\n",
    "    df['MACD'] = macd_line\n",
    "    df['Signal Line'] = signal_line\n",
    "    df['macd_signal'] = macd_line - signal_line\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic_oscillator\n",
    "def calculate_stochastic_oscillator(df, k_fast_period=14, k_slow_period=3, d_slow_period=3, column: str = 'Adj Close'):\n",
    "    \"\"\"\n",
    "    Calculate the Stochastic Oscillator and its corresponding moving averages (K and D lines).\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        k_fast_period (int): The period for the fast %K line.\n",
    "        k_slow_period (int): The period for the slow %K line.\n",
    "        d_slow_period (int): The period for the slow %D line.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with additional columns for %K_fast, %K_slow, %D_fast, and %D_slow.\n",
    "    \"\"\"\n",
    "    # Calculate highest high and lowest low over the period\n",
    "    HH = df['High'].rolling(window=k_fast_period).max()\n",
    "    LL = df['Low'].rolling(window=k_fast_period).min()\n",
    "\n",
    "    # Calculate %K_fast\n",
    "    df['%K_fast'] = ((df[column] - LL) / \n",
    "                     (HH - LL)) * 100\n",
    "    \n",
    "    # Calculate %K_slow (smoothed %K_fast)\n",
    "    df['%K_slow'] = df['%K_fast'].rolling(window=k_slow_period).mean()\n",
    "    \n",
    "    # Calculate %D_fast (3-day SMA of %K_slow)\n",
    "    df['%D_fast'] = df['%K_slow'].rolling(window=d_slow_period).mean()\n",
    "    \n",
    "    # Calculate %D_slow (3-day SMA of %D_fast)\n",
    "    df['%D_slow'] = df['%D_fast'].rolling(window=d_slow_period).mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RSI\n",
    "def calculate_rsi(df, window_size=14, column: str = 'Adj Close'):\n",
    "    \"\"\"\n",
    "    Calculate the Relative Strength Index (RSI) for a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        window (int): The window size for calculating RSI.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with an additional column for RSI.\n",
    "    \"\"\"\n",
    "    # Calculate price changes\n",
    "    delta = df[column].diff()\n",
    "    \n",
    "    # Define up and down moves\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window_size).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window_size).mean()\n",
    "    \n",
    "    # Calculate the relative strength (RS)\n",
    "    rs = gain / loss\n",
    "    \n",
    "    # Calculate RSI\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Store RSI in the DataFrame\n",
    "    df['RSI'] = rsi\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WPR\n",
    "def calculate_williams_percent_r(df, window=14, column: str = 'Adj Close'):\n",
    "    \"\"\"\n",
    "    Calculate the Williams %R (WPR) for a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        window (int): The window size for calculating WPR.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with an additional column for WPR.\n",
    "    \"\"\"\n",
    "    # Calculate highest high and lowest low over the window\n",
    "    highest_high = df['High'].rolling(window=window).max()\n",
    "    lowest_low = df['Low'].rolling(window=window).min()\n",
    "    \n",
    "    # Calculate Williams %R\n",
    "    wpr = ((highest_high - df[column]) / (highest_high - lowest_low)) * -100\n",
    "    \n",
    "    # Store WPR in the DataFrame\n",
    "    df['WPR'] = wpr\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bollinger Bands\n",
    "def calculate_bollinger_bands(df, window=20, num_std_dev=2, column: str = 'Adj Close'):\n",
    "    \"\"\"\n",
    "    Calculate Bollinger Bands for a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        window (int): The window size for the moving average.\n",
    "        num_std_dev (int): The number of standard deviations for the bands.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with additional columns for Bollinger Bands.\n",
    "    \"\"\"\n",
    "    # Calculate rolling mean and standard deviation\n",
    "    rolling_mean = df[column].rolling(window=window).mean()\n",
    "    rolling_std = df[column].rolling(window=window).std()\n",
    "    \n",
    "    # Calculate upper and lower bands\n",
    "    upper_band = rolling_mean + (rolling_std * num_std_dev)\n",
    "    lower_band = rolling_mean - (rolling_std * num_std_dev)\n",
    "    \n",
    "    # Store Bollinger Bands in the DataFrame\n",
    "    df['Bollinger Upper'] = upper_band\n",
    "    df['Bollinger Lower'] = lower_band\n",
    "    df['Bollinger Diff'] = upper_band - lower_band\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On-Balance Volume (OBV)\n",
    "def calculate_obv(df, column: str = 'Adj Close'):\n",
    "    \"\"\"\n",
    "    Calculate On-Balance Volume (OBV) for a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with additional column for OBV.\n",
    "    \"\"\"\n",
    "    obv_values = []\n",
    "    prev_obv = 0\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        if df[column].iloc[i] > df[column].iloc[i - 1]:\n",
    "            obv = prev_obv + df['Volume'].iloc[i]\n",
    "        elif df[column].iloc[i] < df[column].iloc[i - 1]:\n",
    "            obv = prev_obv - df['Volume'].iloc[i]\n",
    "        else:\n",
    "            obv = prev_obv\n",
    "\n",
    "        obv_values.append(obv)\n",
    "        prev_obv = obv\n",
    "\n",
    "    # Add initial OBV value as 0\n",
    "    obv_values = [0] + obv_values\n",
    "\n",
    "    # Store OBV in the DataFrame\n",
    "    df['OBV'] = obv_values\n",
    "\n",
    "    # Convert OBV column to int64\n",
    "    df['OBV'] = df['OBV'].astype('int64')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average True Range (ATR)\n",
    "def calculate_atr(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculate the Average True Range (ATR) of a stock dataset.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing stock data, with 'High', 'Low', and 'Close' columns representing high, low, and closing prices respectively.\n",
    "        period (int): Number of periods for which to calculate the ATR (default is 14).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with 'ATR' column containing the calculated ATR values.\n",
    "    \"\"\"\n",
    "    high = df['High']\n",
    "    low = df['Low']\n",
    "    close = df['Adj Close']\n",
    "    \n",
    "    # True Range (TR) calculation\n",
    "    df['TR'] = df[['High', 'Low', 'Adj Close']].apply(lambda row: max(row['High'] - row['Low'], abs(row['High'] - row['Adj Close']), abs(row['Low'] - row['Adj Close'])), axis=1)\n",
    "    \n",
    "    # ATR calculation\n",
    "    df['ATR'] = df['TR'].rolling(period).mean()\n",
    "    \n",
    "    # Drop the TR column if not needed\n",
    "    df.drop('TR', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rice Rate of Change (ROC)\n",
    "def calculate_roc(df, n_periods=12, column='Adj Close'):\n",
    "    \"\"\"\n",
    "    Calculate the Price Rate of Change (ROC) of a stock dataset.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing stock data, with 'Adj Close' column representing closing prices.\n",
    "        n_periods (int): Number of periods for which to calculate the ROC. # It can be anything such as 12, 25,\n",
    "        or 200. Short-term trader traders typically use a smaller number while longer-term investors use a larger\n",
    "        number.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with 'ROC' column containing the calculated ROC values.\n",
    "    \"\"\"\n",
    "    close_prices = df[column]\n",
    "    close_prices_shifted = close_prices.shift(n_periods)\n",
    "    \n",
    "    roc = ((close_prices - close_prices_shifted) / close_prices_shifted) * 100\n",
    "    \n",
    "    df['ROC'] = roc\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Money Flow Index - MFI\n",
    "def calculate_mfi(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculate the Money Flow Index (MFI) of a stock dataset.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing stock data, with 'High', 'Low', 'Close', and 'Volume' columns representing high, low, closing prices, and volume respectively.\n",
    "        period (int): Number of periods for which to calculate the MFI (default is 14).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with 'MFI' column containing the calculated MFI values.\n",
    "    \"\"\"\n",
    "    high = df['High']\n",
    "    low = df['Low']\n",
    "    close = df['Adj Close']\n",
    "    volume = df['Volume']\n",
    "    \n",
    "    # Typical Price calculation\n",
    "    tp = (high + low + close) / 3\n",
    "    \n",
    "    # Raw Money Flow calculation\n",
    "    mf = tp * volume\n",
    "    \n",
    "    # Determine whether the typical price is higher or lower than the previous period\n",
    "    tp_shifted = tp.shift(1)\n",
    "    positive_flow = (tp > tp_shifted)\n",
    "    negative_flow = (tp < tp_shifted)\n",
    "    \n",
    "    # Calculate positive and negative money flow\n",
    "    positive_mf = positive_flow * mf\n",
    "    negative_mf = negative_flow * mf\n",
    "    \n",
    "    # Calculate the Money Flow Ratio (MFR)\n",
    "    mfr = positive_mf.rolling(window=period).sum() / negative_mf.rolling(window=period).sum()\n",
    "    \n",
    "    # Calculate the Money Flow Index (MFI)\n",
    "    mfi = 100 - (100 / (1 + mfr))\n",
    "    \n",
    "    df['MFI'] = mfi\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chaikin_oscillator\n",
    "def calculate_chaikin_oscillator(df, short_period=3, long_period=10):\n",
    "    \"\"\"\n",
    "    Calculate the Chaikin Oscillator of a stock dataset.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing stock data, with 'High', 'Low', 'Adj Close', and 'Volume' columns representing high, low, closing prices, and volume respectively.\n",
    "        short_period (int): Number of periods for the short EMA (default is 3).\n",
    "        long_period (int): Number of periods for the long EMA (default is 10).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with 'Chaikin_Oscillator' column containing the calculated Chaikin Oscillator values.\n",
    "    \"\"\"\n",
    "    high = df['High']\n",
    "    low = df['Low']\n",
    "    close = df['Adj Close']\n",
    "    volume = df['Volume']\n",
    "    \n",
    "    # Money Flow Multiplier calculation\n",
    "    mfm = ((close - low) - (high - close)) / (high - low)\n",
    "    \n",
    "    # Money Flow Volume calculation\n",
    "    mfv = mfm * volume\n",
    "    \n",
    "    # Accumulation/Distribution Line (ADL) calculation\n",
    "    adl = mfv.cumsum()\n",
    "    \n",
    "    # Calculate the EMA for ADL\n",
    "    ema_short = adl.ewm(span=short_period, min_periods=short_period, adjust=False).mean()\n",
    "    ema_long = adl.ewm(span=long_period, min_periods=long_period, adjust=False).mean()\n",
    "    \n",
    "    # Calculate the Chaikin Oscillator\n",
    "    chaikin_oscillator = ema_short - ema_long\n",
    "    \n",
    "    df['Chaikin_Oscillator'] = chaikin_oscillator\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bulid the technical indicators: features\n",
    "def technical_indicators(df):\n",
    "    df = calculate_sma(df)\n",
    "    df = calculate_wma(df)\n",
    "    df = calculate_macd(df)\n",
    "    df = calculate_rsi(df)\n",
    "    df = calculate_stochastic_oscillator(df)\n",
    "    df = calculate_bollinger_bands(df)\n",
    "    df = calculate_williams_percent_r(df)\n",
    "    df = calculate_obv(df)\n",
    "    df = calculate_roc(df)\n",
    "    df = calculate_atr(df)\n",
    "    df = calculate_mfi(df)\n",
    "    df = calculate_chaikin_oscillator(df)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation Function\n",
    "# Technical analysis indicators need to be rescaled before being fed to the models.\n",
    "# The process is conducted using a version of min-max normalization technique which produces outputs in range from ‐1 to 1.\n",
    "# This technique was chosen for two reasons: it is intuitive as the machine learning models produce output \n",
    "# variable that is also ranging from ‐1 to 1 and because it causes the input data to be more comparable. \n",
    "# X'(t) = (X(t) - min(x)) / (max(x) - min(x))*2 -1\n",
    "\n",
    "def feature_transform(df):\n",
    "    \"\"\"\n",
    "    Transform all columns in the DataFrame as the following formula\n",
    "    X'(t) = (X(t) - min(x)) / (max(x) - min(x))*2 -1\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the calculated technical indicators.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with all columns transformed.\n",
    "    \"\"\"\n",
    "    max_x = df.max(skipna=True)  # Compute maximum values excluding NaN\n",
    "    min_x = df.min(skipna=True)  # Compute minimum values excluding NaN\n",
    "\n",
    "    df_transformed = (df - min_x) / (max_x - min_x) * 2 - 1\n",
    "\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate the dataframe from the biggining so the walk forward splits will continue untill the last date\n",
    "def truncate_before_wf(df, in_sample_size, out_sample_size):\n",
    "    drop_index = (len(df) - in_sample_size) % out_sample_size\n",
    "    return (df.iloc[drop_index:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function returns a list of tuples, where each tuple contains one in-sample \n",
    "#DataFrame and one out-of-sample DataFrame, representing the data splits for each \n",
    "#iteration of the walk-forward validation process.\n",
    "\n",
    "def walk_forward_validation(df, in_sample_size, out_sample_size):\n",
    "    \"\"\"\n",
    "    Perform walk-forward validation on a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        in_sample_size (int): Number of periods to use for in-sample data.\n",
    "        out_sample_size (int): Number of periods to use for out-of-sample data.\n",
    "\n",
    "    Returns:\n",
    "        List: List of tuples that contains the in-sample and out-of-sample data.\n",
    "    \"\"\"\n",
    "    total_rows = len(df)\n",
    "    n_subsets = (total_rows - in_sample_size) // out_sample_size\n",
    "    splits = []\n",
    "        \n",
    "    for i in range(n_subsets):\n",
    "        start_index = i * out_sample_size\n",
    "        end_index = start_index + in_sample_size + out_sample_size\n",
    "        \n",
    "        if end_index > total_rows:\n",
    "            break\n",
    "        \n",
    "        in_sample = df.iloc[start_index : start_index + in_sample_size]\n",
    "        out_of_sample = df.iloc[start_index + in_sample_size : end_index]\n",
    "        \n",
    "        splits.append((in_sample, out_of_sample))\n",
    "    return (splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation coefficients between each feature and the return & print it\n",
    "\n",
    "def correlation(df, target_name):\n",
    "\n",
    "    correlation_with_target = np.abs(df.corrwith(df[target_name]))\n",
    "\n",
    "    # Display the correlation coefficients\n",
    "    print(\"Correlation with Log return:\")\n",
    "    print(correlation_with_target.sort_values(ascending=False))\n",
    "    correlation_with_target.sort_values().plot.barh(color = 'blue',title = 'Strength of Correlation', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus far, we've only used a simple correlation statistic across the full time period. \n",
    "#This is a good place to start but, is a dangerous place to stop. Financial time series data suffers\n",
    "# from non-stationarity and regime change, so a relationship which on average has existed may have been \n",
    "#wildly unstable over time.\n",
    "\n",
    "#To check, we'll plot the rolling correlation of these selected features.\n",
    "\n",
    "# Compute the rolling correlation for each pair of selected features\n",
    "def rolling_correlation(df, target_name, window_size = 200):\n",
    "\n",
    "    correlation_with_target_200 = df.rolling(window=window_size).corr(df[target_name])\n",
    "    # Create traces for each feature\n",
    "    traces = []\n",
    "    for feature in df.columns:\n",
    "        trace = go.Scatter(\n",
    "            x=correlation_with_target_200.index,\n",
    "            y=correlation_with_target_200[feature],\n",
    "            mode='lines',\n",
    "            name=feature\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "    # Create layout for the plot\n",
    "        layout = go.Layout(\n",
    "        title='Rolling Correlation of Features with Log Return',\n",
    "        xaxis=dict(title='Index'),\n",
    "        yaxis=dict(title='Rolling Correlation with Log Return'),\n",
    "        hovermode='closest',\n",
    "        autosize=True\n",
    "    )\n",
    "\n",
    "    # Create figure object\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pair plot\n",
    "def features_paiplot(df):\n",
    "    pairplot = sns.pairplot(df, height=1.5)\n",
    "\n",
    "    # Set the title\n",
    "    pairplot.figure.suptitle('Pairplot of features', y=1.02)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outliers_iqr_df(df, k=1.5):\n",
    "    \"\"\"\n",
    "    Count the number of outliers in each column of the DataFrame using the Interquartile Range (IQR) method.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The input DataFrame.\n",
    "    - k: The multiplier for the IQR. Typically set to 1.5 to 3.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary where keys are column names and values are the number of outliers detected in each column.\n",
    "    \"\"\"\n",
    "    outliers_counts = {}\n",
    "    for col in df.columns:\n",
    "        data = df[col]\n",
    "        quartile_1, quartile_3 = np.percentile(data, [25, 75])\n",
    "        iqr = quartile_3 - quartile_1\n",
    "        lower_bound = quartile_1 - (k * iqr)\n",
    "        upper_bound = quartile_3 + (k * iqr)\n",
    "        outliers = (data < lower_bound) | (data > upper_bound)\n",
    "        outliers_counts[col] = np.sum(outliers)\n",
    "    return outliers_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Truncate NaN Data\n",
    "def drop_nan(df):\n",
    "    # Remove rows with NaN values\n",
    "    cleaned_df = df.dropna()\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check distribution \n",
    "def check_distribution(df, column_name='Adj Close'):\n",
    "    \"\"\"\n",
    "    Check the distribution of a column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        column_name (str): Name of the column to check the distribution for (default is 'Adj Close').\n",
    "\n",
    "    Returns:\n",
    "        None (displays descriptive statistics and visualizations)\n",
    "    \"\"\"\n",
    "    # Descriptive statistics\n",
    "    print(\"Descriptive Statistics:\")\n",
    "    print(df[column_name].describe())\n",
    "\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column_name], kde=True)\n",
    "    plt.title(f'Distribution of {column_name}')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_normal(df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test if the data is normally distributed using Z-score.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The input data array.\n",
    "    - alpha: The significance level for the test.\n",
    "    \n",
    "    Returns:\n",
    "    - True if the data is normally distributed, False otherwise.\n",
    "    \"\"\"\n",
    "    normal_col = {}\n",
    "    for col in df.columns:\n",
    "        data = df[col]\n",
    "        z_score, p_value = stats.normaltest(data)\n",
    "        normal_col[col] = p_value > alpha\n",
    "    return normal_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate Mean Absolute Percentage Error (MAPE)\n",
    "    \n",
    "    Args:\n",
    "    actual: array-like, actual values\n",
    "    predicted: array-like, predicted values\n",
    "    \n",
    "    Returns:\n",
    "    mape: float, MAPE value\n",
    "    \"\"\"\n",
    "    # Ensure both actual and predicted arrays have the same length\n",
    "    if len(actual) != len(predicted):\n",
    "        raise ValueError(\"Length of actual and predicted arrays must be the same.\")\n",
    "    \n",
    "\n",
    "    # Calculate absolute percentage error for each observation\n",
    "    abs_percentage_error = np.abs((actual - predicted) / np.maximum(np.abs(actual), 1e-10))\n",
    "    \n",
    "    # Calculate mean of absolute percentage errors\n",
    "    mape = np.mean(abs_percentage_error) * 100\n",
    "    \n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_buy_and_hold_returns(df, column_to_diff='Predictions', column='Predicted Returns'):\n",
    "    \"\"\"\n",
    "    Calculate returns from adjusted close prices of the bench mark buy and hold strategy.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing adjusted close prices.\n",
    "\n",
    "    Returns:\n",
    "    returns (DataFrame): DataFrame containing the calculated returns in df[column].\n",
    "    \"\"\"\n",
    "    initial_value = df.iloc[0][column_to_diff]\n",
    "    df[column] = (df[column_to_diff] - initial_value)/initial_value\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sharpe_ratio(df, column, risk_free_rate=0.0, annualized=True):\n",
    "    \"\"\"\n",
    "    Calculate the Sharpe Ratio for the S&P 500 index.\n",
    "\n",
    "    Parameters:\n",
    "    - sp500_df: DataFrame containing historical S&P 500 index data with a 'Close' column.\n",
    "    - risk_free_rate: Annualized risk-free rate of return (default is 0.0).\n",
    "    - annualized: If True, return annualized Sharpe Ratio; if False, return non-annualized Sharpe Ratio (default is True).\n",
    "\n",
    "    Returns:\n",
    "    - sharpe_ratio: The calculated Sharpe Ratio.\n",
    "    \"\"\"\n",
    "    # Calculate excess returns (returns above risk-free rate)\n",
    "    excess_returns = df[column] - risk_free_rate / 252  # Assuming 252 trading days in a year\n",
    "\n",
    "    # Calculate Sharpe Ratio\n",
    "    sharpe_ratio = excess_returns.mean() / excess_returns.std()\n",
    "\n",
    "    # Annualize Sharpe Ratio if required\n",
    "    if annualized:\n",
    "        sharpe_ratio *= (252 ** 0.5)\n",
    "\n",
    "    return sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ir(stock_returns, benchmark_returns):\n",
    "    \"\"\"\n",
    "    Calculate the Information Ratio (IR) for a stock compared to a benchmark.\n",
    "\n",
    "    Parameters:\n",
    "    - stock_returns: Array-like object containing historical returns of the stock.\n",
    "    - benchmark_returns: Array-like object containing historical returns of the benchmark.\n",
    "\n",
    "    Returns:\n",
    "    - ir: The calculated Information Ratio.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Calculate excess returns\n",
    "    excess_returns = stock_returns - benchmark_returns\n",
    "    \n",
    "    # Step 2: Calculate average excess return\n",
    "    avg_excess_return = np.mean(excess_returns)\n",
    "    \n",
    "    # Step 3: Calculate standard deviation of excess returns\n",
    "    std_excess_return = np.std(excess_returns)\n",
    "    \n",
    "    # Step 4: Calculate Information Ratio\n",
    "    ir = avg_excess_return / std_excess_return\n",
    "    \n",
    "    return ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mdd(returns):\n",
    "    \"\"\"\n",
    "    Calculate the Maximum Drawdown (MDD) of a time series of returns.\n",
    "\n",
    "    Parameters:\n",
    "    - returns: Array-like object containing historical returns.\n",
    "\n",
    "    Returns:\n",
    "    - max_drawdown: The calculated Maximum Drawdown.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate cumulative returns\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    \n",
    "    # Calculate the maximum value seen up to each point\n",
    "    max_seen = cum_returns.cummax()\n",
    "    \n",
    "    # Calculate drawdowns\n",
    "    drawdowns = (cum_returns - max_seen) / max_seen\n",
    "    \n",
    "    # Find the maximum drawdown\n",
    "    max_drawdown = drawdowns.min()\n",
    "    \n",
    "    return max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(true_series, predicted_series):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a model that predicts buy, hold, or sell signals.\n",
    "\n",
    "    Parameters:\n",
    "    true_series (Series): Pandas Series containing true labels.\n",
    "    predicted_series (Series): Pandas Series containing predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    accuracy (float): Accuracy of the model.\n",
    "    \"\"\"\n",
    "    if len(true_series) != len(predicted_series):\n",
    "        raise ValueError(\"The lengths of true_series and predicted_series must be equal.\")\n",
    "\n",
    "    correct_predictions = sum(1 for true_label, predicted_label in zip(true_series,\n",
    "                             predicted_series) if true_label == predicted_label)\n",
    "    total_predictions = len(true_series)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(df, column_to_diff='Predictions', column='Predicted Returns'):\n",
    "    \"\"\"\n",
    "    Calculate returns from adjusted close prices.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing adjusted close prices.\n",
    "\n",
    "    Returns:\n",
    "    returns (DataFrame): DataFrame containing the calculated returns in df[column].\n",
    "    \"\"\"\n",
    "    \n",
    "    df[column] = df[column_to_diff].pct_change()\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quantiles(df, column='Predected Return', q1=0.25, q2=0.5, q3=0.75):\n",
    "    \"\"\"\n",
    "    Calculate specified quantiles (percentiles) of a column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - column: Name of the column for which quantiles are to be calculated (default is 'Predicted Return').\n",
    "    - q1: The percentile to calculate for the first quartile (default is 0.25, corresponding to the 25th percentile).\n",
    "    - q2: The percentile to calculate for the second quartile (default is 0.5, corresponding to the median).\n",
    "    - q3: The percentile to calculate for the third quartile (default is 0.75, corresponding to the 75th percentile).\n",
    "\n",
    "    Returns:\n",
    "    - quantiles: A tuple containing the specified quantiles (Q1, Q2, Q3).\n",
    "    \"\"\"\n",
    "    \n",
    "    Q1 = df[column].quantile(q1)\n",
    "    Q2 = df[column].quantile(q2)  # Median\n",
    "    Q3 = df[column].quantile(q3)\n",
    "\n",
    "    return (Q1, Q2, Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_signal(df, return_column='Predicted Returns', signal_column='Predicted Signal', q1=None, q3=None):\n",
    "    \"\"\"\n",
    "    Calculate trading signals based on specified quantiles of returns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - return_column: Name of the column containing returns (default is 'Predicted Returns').\n",
    "    - signal_column: Name of the column to store the calculated signals (default is 'Predicted Signal').\n",
    "    - q1: The percentile to calculate for the first quartile (default is None, calculated as 0.25 quantile if not provided).\n",
    "    - q3: The percentile to calculate for the third quartile (default is None, calculated as 0.75 quantile if not provided).\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with the added signal_column containing the calculated signals.\n",
    "    \"\"\"\n",
    "    if q1 is None or q3 is None:\n",
    "        q1 = df[return_column].quantile(0.25)\n",
    "        q3 = df[return_column].quantile(0.75)\n",
    "\n",
    "    df[signal_column] = 0  # Default signal\n",
    "\n",
    "    df.loc[df[return_column] >= q3, signal_column] = 1\n",
    "    df.loc[df[return_column] <= q1, signal_column] = -1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_creation(df, col_names:list, y_col_name='Adj Close',):\n",
    "    df = calculate_sma(df.copy())\n",
    "    df = calculate_wma(df.copy())\n",
    "    df = calculate_macd(df.copy())\n",
    "    df = calculate_rsi(df.copy())\n",
    "    df = calculate_stochastic_oscillator(df.copy())\n",
    "    df = calculate_bollinger_bands(df.copy())\n",
    "    df = calculate_williams_percent_r(df.copy())\n",
    "    df = calculate_obv(df.copy())\n",
    "    df = calculate_roc(df.copy())\n",
    "    df = calculate_atr(df.copy())\n",
    "    df = calculate_mfi(df.copy())\n",
    "    df = calculate_chaikin_oscillator(df.copy())\n",
    "\n",
    "    #drop NA data\n",
    "    df = df.dropna()\n",
    "\n",
    "    #Choose the specific features\n",
    "    df = df[col_names]\n",
    "\n",
    "    #transform features [-1,1]\n",
    "    dfX = df.copy()\n",
    "    dfX = dfX.drop(columns=y_col_name)\n",
    "    dfX = feature_transform(dfX)\n",
    "    df = pd.concat([dfX, df[y_col_name]],axis= 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_creation_to_splits(splits, col_names:list, y_col_name='Adj Close'):\n",
    "    \"\"\"\n",
    "    Apply feature creation function to each split and return a list of tuples containing processed \n",
    "    in-sample DataFrame along with the corresponding out-of-sample DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        splits (list): List of tuples containing in-sample and out-of-sample DataFrames.\n",
    "        col_names (list): List of column names to select from the DataFrame.\n",
    "        y_col_name (str): Name of the target column.\n",
    "\n",
    "    Returns:\n",
    "        list: List of tuples containing processed in-sample DataFrame and corresponding out-of-sample \n",
    "        DataFrame.\n",
    "    \"\"\"\n",
    "    processed_splits = []  # List to store processed splits\n",
    "    \n",
    "    # Iterate over each split\n",
    "    for split in splits:\n",
    "        in_sample, out_of_sample = split  # Unpack the split\n",
    "        \n",
    "        # Apply features_creation to the in-sample data\n",
    "        in_sample_features = features_creation(in_sample, col_names=col_names, y_col_name=y_col_name)\n",
    "        \n",
    "        # Apply features_creation to the in-sample data\n",
    "        out_of_sample_features = features_creation(out_of_sample, col_names=col_names, y_col_name=y_col_name)\n",
    "        \n",
    "        # Append the processed in-sample DataFrame along with the original out-of-sample DataFrame to the list\n",
    "        processed_splits.append((in_sample_features, out_of_sample_features))\n",
    "    \n",
    "    return processed_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy and add features\n",
    "sp500 = sp500_data.copy()\n",
    "sp500 = technical_indicators(sp500)\n",
    "sp500_val = sp500_validation_set.copy()\n",
    "sp500_val = technical_indicators(sp500_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform features\n",
    "sp500.iloc[:, 6:] = sp500.iloc[:, 6:].apply(feature_transform, axis=0)\n",
    "sp500_val.iloc[:, 6:] = sp500_val.iloc[:, 6:].apply(feature_transform, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NA\n",
    "sp500 = sp500.dropna()\n",
    "sp500_val = sp500_val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation before choosing features\n",
    "#correlation(sp500, 'Adj Close')\n",
    "#rolling_correlation(sp500, 'Adj Close')\n",
    "\n",
    "# Step 1: Take the most strongly correlated feature and add it to our list of selected features. \n",
    "# Step 2: Take the second correlated feature and check to see if it's closely correlated \n",
    "# (neighboring in the clustermap) to any features already chosen.\n",
    "# If no, add to the list. If yes, discard. \n",
    "# Step 3: Repeat this process until either (1) we've reached the target feature count,\n",
    "# or (2) we've run out strongly correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the data from na values & pick the columns\n",
    "sp500_d = sp500.copy()\n",
    "sp500_d = drop_nan(sp500_d)\n",
    "sp500_d = sp500_d.loc[:, ['SMA','WMA', 'MACD', 'RSI', '%K_fast', '%D_fast', '%D_slow', 'Bollinger Diff',\n",
    "                    'WPR', 'OBV', 'ROC', 'ATR', 'MFI', 'Chaikin_Oscillator', 'Adj Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_distribution(sp500_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the correlated data:\n",
    "#features_paiplot(sp500_d)\n",
    "#correlation(sp500_d, 'Adj Close')\n",
    "rolling_correlation(sp500, 'Adj Close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is data normal?\", is_normal(sp500_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_counts = count_outliers_iqr_df(sp500_d)\n",
    "print(\"Number of outliers in each column:\")\n",
    "print(outliers_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the context of regression tasks like this one (since SVR is a Support Vector Machine for regression),\n",
    "# where the target variable is continuous (e.g., log returns), a model score less than 0 typically indicates \n",
    "# that the model is performing poorly and making predictions that are worse than simply using the mean or another\n",
    "# basic statistical measure as the prediction for all samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arima Model without Time Sieries Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the data from na values & pick the columns\n",
    "data = sp500.copy()\n",
    "data = drop_nan(data)\n",
    "data = data.loc[:, chosen_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = walk_forward_validation(data, 320, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto ARIMA to select optimal ARIMA parameters\n",
    "model = auto_arima(data['Adj Close'], seasonal=False, trace=True)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Arima Model is ARIMA(2,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data Splitted 80% - 20% - Walk Forward on test (the predictions added to the train)\n",
    "The Method of WF as it was used for other Models WAS NOT USED HERE!!!\n",
    "The Predictions were really bad when it was tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ex_df = data['Adj Close']\n",
    "# Define the ARIMA model\n",
    "def arima_forecast(history):\n",
    "    # Fit the model\n",
    "    model = ARIMA(history, order=(2,1,2))\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Make the prediction\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    return yhat\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = dataset_ex_df.values\n",
    "size = int(len(X) * 0.8)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "# Walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "    # Generate a prediction\n",
    "    yhat = arima_forecast(history)\n",
    "    predictions.append(yhat)\n",
    "    # Add the predicted value to the training set\n",
    "    obs = test[t]\n",
    "    history.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARIMAModel:\n",
    "    def __init__(self, order=(2, 1, 2)):\n",
    "        self.order = order\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, history):\n",
    "        self.model = ARIMA(history, order=self.order)\n",
    "        self.model_fit = self.model.fit()\n",
    "    \n",
    "    def forecast(self):\n",
    "        if self.model is None:\n",
    "            raise Exception(\"Model not fitted yet. Call fit() method first.\")\n",
    "        return self.model_fit.forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ex_df = data['Adj Close']\n",
    "# Split data into train and test sets\n",
    "X = dataset_ex_df.values\n",
    "size = int(len(X) * 0.8)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "# Walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = []\n",
    "\n",
    "# Instantiate ARIMAModel\n",
    "arima_model = ARIMAModel()\n",
    "\n",
    "# Fit the model and make predictions\n",
    "for t in range(len(test)):\n",
    "    arima_model.fit(history)\n",
    "    yhat = arima_model.forecast()[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arima Train set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "mae = mean_absolute_error(test,predictions)\n",
    "mse = mean_squared_error(test,predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(test,predictions)\n",
    "mape = mean_absolute_percentage_error(test,predictions)\n",
    "\n",
    "# Visualize predictions vs. actual values\n",
    "plt.scatter(test,predictions)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}\\nMean Squared Error: {mse}\\nRoot Mean Squared Error: {rmse}\\nR-squared: {r2}')\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "# Create traces\n",
    "trace1 = go.Scatter(x=dataset_ex_df.iloc[size:].index, y=test, mode='lines', name='Adjusted Close')\n",
    "trace2 = go.Scatter(x=dataset_ex_df.iloc[size:].index, y=predictions, mode='lines', name='Adj_Close_diff')\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces to figure\n",
    "fig.add_trace(trace1)\n",
    "fig.add_trace(trace2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='ARIMA Predictions vs Actual Values',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='USD',\n",
    "                  hovermode='x unified')\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arima Validation set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ex_df = sp500_val['Adj Close']\n",
    "# Define the ARIMA model\n",
    "def arima_forecast(history):\n",
    "    # Fit the model\n",
    "    model = ARIMA(history, order=(2,1,2))\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Make the prediction\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    return yhat\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = dataset_ex_df.values\n",
    "#size = int(len(X) * 0.8)\n",
    "#train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "# Walk-forward prediction\n",
    "history = X[0]\n",
    "predictions = list()\n",
    "for t in range(len(X)):\n",
    "    # Generate a prediction\n",
    "    yhat = arima_forecast(history)\n",
    "    predictions.append(yhat)\n",
    "    # Add the predicted value to the training set\n",
    "    obs = X[t]\n",
    "    history.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate\n",
    "mae = mean_absolute_error(X,predictions)\n",
    "mse = mean_squared_error(X,predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(test,predictions)\n",
    "mape = mean_absolute_percentage_error(test,predictions)\n",
    "# Visualize predictions vs. actual values\n",
    "plt.scatter(test,predictions)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}\\nMean Squared Error: {mse}\\nRoot Mean Squared Error: {rmse}\\nR-squared: {r2}')\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "# Create traces\n",
    "trace1 = go.Scatter(x=dataset_ex_df.iloc[size:].index, y=X, mode='lines', name='Adjusted Close')\n",
    "trace2 = go.Scatter(x=dataset_ex_df.iloc[size:].index, y=predictions, mode='lines', name='Adj_Close_diff')\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces to figure\n",
    "fig.add_trace(trace1)\n",
    "fig.add_trace(trace2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='ARIMA Predictions vs Actual Values',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='USD',\n",
    "                  hovermode='x unified')\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class For All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesModels:\n",
    "    def __init__(self, k=5, svr_kernel='rbf', C=1.0, gamma=0.1, degree=3, rf_n_estimators=100, rf_max_features=4, \n",
    "                 rf_criterion = 'squared_error', gbm_n_estimators=100, gbm_criterion='squared_error',\n",
    "                 gbm_loss='squared_error', gbm_n_features='sqrt'):\n",
    "\n",
    "        self.k = k\n",
    "        self.svr_kernel = svr_kernel\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.C = C\n",
    "        self.rf_n_estimators = rf_n_estimators\n",
    "        self.rf_max_features = rf_max_features\n",
    "        self.rf_criterion = rf_criterion\n",
    "        self.gbm_n_estimators = gbm_n_estimators\n",
    "        self.gbm_criterion = gbm_criterion\n",
    "        self.gbm_loss = gbm_loss\n",
    "        self.gbm_n_features = gbm_n_features\n",
    "\n",
    "        # Initialize models\n",
    "        self.knn_model = KNeighborsRegressor(n_neighbors=self.k)\n",
    "        self.svr_model = SVR(kernel=self.svr_kernel, gamma=self.gamma, degree=self.degree, C=self.C)\n",
    "        self.rf_model = RandomForestRegressor(n_estimators=self.rf_n_estimators,\n",
    "                         max_features=self.rf_max_features, criterion=self.rf_criterion, bootstrap=False, warm_start=True)\n",
    "        self.gbm_model = GradientBoostingRegressor(n_estimators=self.gbm_n_estimators, \n",
    "                                                   criterion=self.gbm_criterion, loss=self.gbm_loss\n",
    "                                                   ,max_features=self.gbm_n_features)\n",
    "        self.lr_model = LinearRegression()\n",
    "\n",
    "    def knn_fit(self, dfX, vY):\n",
    "        self.knn_model.fit(dfX, vY)\n",
    "\n",
    "    def svr_fit(self, dfX, vY):\n",
    "        self.svr_model.fit(dfX, vY)\n",
    "\n",
    "    def rf_fit(self, dfX, vY):\n",
    "        self.rf_model.fit(dfX, vY)\n",
    "\n",
    "    def gbm_fit(self, dfX, vY):\n",
    "        self.gbm_model.fit(dfX, vY)\n",
    "    \n",
    "    def lr_fit(self, dfX, vY):\n",
    "        self.lr_model.fit(dfX, vY)\n",
    "\n",
    "    def knn_predict(self, dfX):\n",
    "        return self.knn_model.predict(dfX)\n",
    "\n",
    "    def svr_predict(self, dfX):\n",
    "        return self.svr_model.predict(dfX)\n",
    "\n",
    "    def rf_predict(self, dfX):\n",
    "        return self.rf_model.predict(dfX)\n",
    "\n",
    "    def gbm_predict(self, dfX):\n",
    "        return self.gbm_model.predict(dfX)\n",
    "    \n",
    "    def lr_predict(self, dfX):\n",
    "        return self.lr_model.predict(dfX)\n",
    "\n",
    "    def knn_score(self, dfX, vY):\n",
    "        return self.knn_model.score(dfX, vY)\n",
    "\n",
    "    def svr_score(self, dfX, vY):\n",
    "        return self.svr_model.score(dfX, vY)\n",
    "\n",
    "    def rf_score(self, dfX, vY):\n",
    "        return self.rf_model.score(dfX, vY)\n",
    "\n",
    "    def gbm_score(self, dfX, vY):\n",
    "        return self.gbm_model.score(dfX, vY)\n",
    "    \n",
    "    def lr_score(self, dfX, vY):\n",
    "        return self.lr_model.score(dfX, vY)\n",
    "\n",
    "    def knn_train(self, splits, col_drop):\n",
    "        predictions = []\n",
    "        \n",
    "        for i, (in_sample, out_of_sample) in enumerate(splits):\n",
    "            X_train = in_sample.drop(columns=[col_drop])\n",
    "            y_train = in_sample[col_drop]\n",
    "            self.knn_model.fit(X_train, y_train)\n",
    "\n",
    "            X_test = out_of_sample.drop(columns=[col_drop])\n",
    "            # Create an array of NaN values with the same length as the NaN window\n",
    "            nan_values = np.full(19, np.nan)\n",
    "            prediction = self.knn_model.predict(X_test)\n",
    "            # Concatenate NaN values with the non-NaN part of the predictions\n",
    "            aligned_predictions = np.concatenate([nan_values, prediction])\n",
    "            predictions.extend(aligned_predictions)\n",
    "        return (predictions)\n",
    "    \n",
    "    def svr_train(self, splits, col_drop):\n",
    "        predictions = []\n",
    "        for i, (in_sample, out_of_sample) in enumerate(splits):\n",
    "            X_train = in_sample.drop(columns=[col_drop])\n",
    "            y_train = in_sample[col_drop]\n",
    "            self.svr_model.fit(X_train, y_train)\n",
    "\n",
    "            X_test = out_of_sample.drop(columns=[col_drop])\n",
    "            # Create an array of NaN values with the same length as the NaN window\n",
    "            nan_values = np.full(19, np.nan)\n",
    "            prediction = self.svr_model.predict(X_test)\n",
    "            # Concatenate NaN values with the non-NaN part of the predictions\n",
    "            aligned_predictions = np.concatenate([nan_values, prediction])\n",
    "            predictions.extend(aligned_predictions)\n",
    "        return (predictions)\n",
    "    \n",
    "    def rf_train(self, splits, col_drop):\n",
    "        predictions = []\n",
    "        for i, (in_sample, out_of_sample) in enumerate(splits):\n",
    "            X_train = in_sample.drop(columns=[col_drop])\n",
    "            y_train = in_sample[col_drop]\n",
    "            self.rf_model.fit(X_train, y_train)\n",
    "\n",
    "            X_test = out_of_sample.drop(columns=[col_drop])\n",
    "            # Create an array of NaN values with the same length as the NaN window\n",
    "            nan_values = np.full(19, np.nan)\n",
    "            prediction = self.rf_model.predict(X_test)\n",
    "            # Concatenate NaN values with the non-NaN part of the predictions\n",
    "            aligned_predictions = np.concatenate([nan_values, prediction])\n",
    "            predictions.extend(aligned_predictions)\n",
    "        return (predictions)\n",
    "\n",
    "    def gbm_train(self, splits, col_drop):\n",
    "        predictions = []\n",
    "        for i, (in_sample, out_of_sample) in enumerate(splits):\n",
    "            X_train = in_sample.drop(columns=[col_drop])\n",
    "            y_train = in_sample[col_drop]\n",
    "            self.gbm_model.fit(X_train, y_train)\n",
    "\n",
    "            X_test = out_of_sample.drop(columns=[col_drop])\n",
    "            # Create an array of NaN values with the same length as the NaN window\n",
    "            nan_values = np.full(19, np.nan)\n",
    "            prediction = self.gbm_model.predict(X_test)\n",
    "            # Concatenate NaN values with the non-NaN part of the predictions\n",
    "            aligned_predictions = np.concatenate([nan_values, prediction])\n",
    "            predictions.extend(aligned_predictions)\n",
    "        return (predictions)\n",
    "    \n",
    "    def lr_train(self, splits, col_drop):\n",
    "        predictions = []\n",
    "        for i, (in_sample, out_of_sample) in enumerate(splits):\n",
    "            X_train = in_sample.drop(columns=[col_drop])\n",
    "            y_train = in_sample[col_drop]\n",
    "            self.lr_model.fit(X_train, y_train)\n",
    "\n",
    "            X_test = out_of_sample.drop(columns=[col_drop])\n",
    "            # Create an array of NaN values with the same length as the NaN window\n",
    "            nan_values = np.full(19, np.nan)\n",
    "            prediction = self.lr_model.predict(X_test)\n",
    "            # Concatenate NaN values with the non-NaN part of the predictions\n",
    "            aligned_predictions = np.concatenate([nan_values, prediction])\n",
    "            predictions.extend(aligned_predictions)\n",
    "        return (predictions)\n",
    "    \n",
    "    def evaluate(self, y_true, y_pred):\n",
    "        self.mae = mean_absolute_error(y_true, y_pred)\n",
    "        self.mse = mean_squared_error(y_true, y_pred)\n",
    "        self.rmse = np.sqrt(self.mse)\n",
    "        self.r2 = r2_score(y_true, y_pred)\n",
    "        self.mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "        return (self.mae, self.mse, self.rmse, self.r2, self.mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk Forward Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sp500.copy()\n",
    "\n",
    "data = drop_nan(data)\n",
    "data = data.loc[:, ['SMA','WMA', 'MACD', 'RSI', '%K_fast', '%D_fast', '%D_slow', 'Bollinger Diff',\n",
    "                    'WPR', 'OBV', 'ROC', 'ATR', 'MFI', 'Chaikin_Oscillator', 'Adj Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalize the dataframe\n",
    "sp500_d_WF_splits = data.copy()\n",
    "\n",
    "#Allocate columns for results\n",
    "sp500_d_WF_splits['Prediction_8'] = np.nan\n",
    "sp500_d_WF_splits['Prediction_12'] = np.nan\n",
    "sp500_d_WF_splits['Prediction_20'] = np.nan\n",
    "sp500_d_WF_splits['Prediction_50'] = np.nan\n",
    "sp500_d_WF_splits['Prediction_100'] = np.nan\n",
    "sp500_d_WF_splits['Prediction_200'] = np.nan\n",
    "sp500_d_WF_splits['Prediction_300'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model that was chosen to be perform the test with is Gbm\n",
    "Model = TimeSeriesModels(gbm_n_estimators=100, gbm_criterion='squared_error', gbm_loss='squared_error', gbm_n_features=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(data, results_set, val_set, Model, num_splits, col_name='Adj Close'):\n",
    "    result = {'R2': [], 'RMSE': [], 'R2_Val': [], 'RMSE_Val': []}\n",
    "    \n",
    "    for num_split in num_splits:\n",
    "        x = len(data) // (num_split + 4)\n",
    "        truncated_data = truncate_before_wf(data.copy(), 4 * x, x)\n",
    "        splits = walk_forward_validation(truncated_data, 4 * x, x)\n",
    "        \n",
    "        predictions = Model.gbm_train(splits, col_name)\n",
    "        train_column_name = f'Prediction_{num_split}'\n",
    "        start_index = 4 * x\n",
    "        results_set.iloc[start_index:start_index + len(predictions), results_set.columns.get_loc(train_column_name)] = predictions\n",
    "        \n",
    "        filtered_df = results_set.dropna(subset=[train_column_name])\n",
    "        column1_values = filtered_df[col_name]\n",
    "        column2_values = filtered_df[train_column_name]\n",
    "        \n",
    "        _, _, rmse, r2, _ = Model.evaluate(column1_values, column2_values)\n",
    "        result['R2'].append(r2)\n",
    "        result['RMSE'].append(rmse)\n",
    "        \n",
    "        # Evaluate on validation data\n",
    "        feat_dfX = val_set.drop(columns=col_name)\n",
    "        predictions_val = Model.gbm_predict(feat_dfX)\n",
    "        #val_column_name = f'Val_with_{num_split}_splits'\n",
    "        #val_set[val_column_name] = predictions_val\n",
    "        \n",
    "        _, _, rmse_val, r2_val, _ = Model.evaluate(val_set[col_name], predictions_val)\n",
    "        result['R2_Val'].append(r2_val)\n",
    "        result['RMSE_Val'].append(rmse_val)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = sp500_val.copy()\n",
    "dfX = dfX.loc[:, ['SMA','WMA', 'MACD', 'RSI', '%K_fast', '%D_fast', '%D_slow', 'Bollinger Diff',\n",
    "                    'WPR', 'OBV', 'ROC', 'ATR', 'MFI', 'Chaikin_Oscillator', 'Adj Close']]\n",
    "\n",
    "# Example usage:\n",
    "num_splits = [8, 12, 20, 50, 100, 200, 300]  # List of number of splits to evaluate\n",
    "results = evaluate_model_performance(data, sp500_d_WF_splits, dfX, Model, num_splits)\n",
    "# initiate a list to contain R2, RMSE values of each model\n",
    "R2_training_set = results['R2']\n",
    "RMSE = results['RMSE']\n",
    "\n",
    "# initiate a list to contain R2, RMSE values of each model\n",
    "R2_validation_set = results['R2_Val']\n",
    "RMSE_validation_set = results['RMSE_Val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Present results R2 train set\n",
    "splits = [8, 12, 20, 50, 100, 200, 300]\n",
    "# Plot list2 against list1\n",
    "plt.plot(splits, R2_training_set, marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Splits - Train Data')\n",
    "plt.ylabel('R2 - Gradient Boosting')\n",
    "plt.title('R2 vs. Splits Number')\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present results r2 val set\n",
    "splits = [8, 12, 20, 50, 100, 200, 300]\n",
    "# Plot R2 for validation set\n",
    "plt.plot(splits, R2_validation_set, marker='o', linestyle='-', label='Validation Set')\n",
    "\n",
    "# Plot R2 for training set\n",
    "plt.plot(splits, R2_training_set, marker='o', linestyle='-', label='Training Set')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Splits - Validation Data')\n",
    "plt.ylabel('R2 - Gradient Boosting')\n",
    "plt.title('R2 vs. Splits Number')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE for train set\n",
    "splits = [8, 12, 20, 50, 100, 200, 300]\n",
    "\n",
    "# Plot list2 against list1\n",
    "plt.plot(splits, RMSE, marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Splits - Train Data')\n",
    "plt.ylabel('RMSE - Gradient Boosting')\n",
    "plt.title('RMSE vs. Splits Number')\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present results rmse val set\n",
    "splits = [8, 12, 20, 50, 100, 200, 300]\n",
    "# Plot RMSE for validation set\n",
    "plt.plot(splits, RMSE_validation_set, marker='o', linestyle='-', label='Validation Set')\n",
    "\n",
    "# Plot RMSE for training set\n",
    "plt.plot(splits, RMSE, marker='o', linestyle='-', label='Training Set')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Splits - Validation Data')\n",
    "plt.ylabel('RMSE - Gradient Boosting')\n",
    "plt.title('RMSE vs. Splits Number')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty figure\n",
    "fig = go.Figure()\n",
    "df_columns = ['Adj Close', 'Prediction_8', 'Prediction_12', 'Prediction_20', 'Prediction_50', 'Prediction_100', 'Prediction_200', 'Prediction_300']\n",
    "# Iterate over columns and add each one to the figure with a different color\n",
    "for col in df_columns:\n",
    "    fig.add_trace(go.Scatter(x=sp500_d_WF_splits.index, y=sp500_d_WF_splits[col], mode='lines', name=col))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Prediction with Gradient Boosting Model, with different number of data splits\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Value\",\n",
    "    legend=dict(title=\"Columns\")\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the ratio between Out_of_sample data and in_sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose 50 splits\n",
    "\n",
    "def evaluate_model_performance(data, results_set, val_set, Model, oos_ins_raio, split_n=50, col_name='Adj Close'):\n",
    "    result = {'R2': [], 'RMSE': [], 'R2_Val': [], 'RMSE_Val': []}\n",
    "    \n",
    "    for ratio in oos_ins_raio:\n",
    "        x = len(data) // (split_n + ratio)\n",
    "        truncated_data = truncate_before_wf(data.copy(), ratio * x, x)\n",
    "        splits = walk_forward_validation(truncated_data, ratio * x, x)\n",
    "        \n",
    "        predictions = Model.gbm_train(splits, col_name)\n",
    "        train_column_name = f'Prediction_{ratio}'\n",
    "        start_index = ratio * x\n",
    "        results_set.iloc[start_index:start_index + len(predictions), results_set.columns.get_loc(train_column_name)] = predictions\n",
    "        \n",
    "        filtered_df = results_set.dropna(subset=[train_column_name])\n",
    "        column1_values = filtered_df[col_name]\n",
    "        column2_values = filtered_df[train_column_name]\n",
    "        \n",
    "        _, _, rmse, r2, _ = Model.evaluate(column1_values, column2_values)\n",
    "        result['R2'].append(r2)\n",
    "        result['RMSE'].append(rmse)\n",
    "        \n",
    "        # Evaluate on validation data\n",
    "        feat_dfX = val_set.drop(columns=col_name)\n",
    "        predictions_val = Model.gbm_predict(feat_dfX)\n",
    "        #val_column_name = f'Val_with_{num_split}_splits'\n",
    "        #val_set[val_column_name] = predictions_val\n",
    "        \n",
    "        _, _, rmse_val, r2_val, _ = Model.evaluate(val_set[col_name], predictions_val)\n",
    "        result['R2_Val'].append(r2_val)\n",
    "        result['RMSE_Val'].append(rmse_val)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sp500.copy()\n",
    "\n",
    "data = drop_nan(data)\n",
    "data = data.loc[:, ['SMA','WMA', 'MACD', 'RSI', '%K_fast', '%D_fast', '%D_slow', 'Bollinger Diff',\n",
    "                    'WPR', 'OBV', 'ROC', 'ATR', 'MFI', 'Chaikin_Oscillator', 'Adj Close']]\n",
    "\n",
    "#Initalize the dataframe\n",
    "sp500_ratio = data.copy()\n",
    "\n",
    "#Allocate columns for results\n",
    "sp500_ratio['Prediction_2'] = np.nan\n",
    "sp500_ratio['Prediction_3'] = np.nan\n",
    "sp500_ratio['Prediction_4'] = np.nan\n",
    "sp500_ratio['Prediction_5'] = np.nan\n",
    "sp500_ratio['Prediction_6'] = np.nan\n",
    "sp500_ratio['Prediction_7'] = np.nan\n",
    "sp500_ratio['Prediction_8'] = np.nan\n",
    "sp500_ratio['Prediction_9'] = np.nan\n",
    "sp500_ratio['Prediction_10'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model that was chosen to be perform the test with is Gbm\n",
    "Model = TimeSeriesModels(gbm_n_estimators=100, gbm_criterion='squared_error', gbm_loss='squared_error', gbm_n_features=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = sp500_val.copy()\n",
    "dfX = dfX.loc[:, ['SMA','WMA', 'MACD', 'RSI', '%K_fast', '%D_fast', '%D_slow', 'Bollinger Diff',\n",
    "                    'WPR', 'OBV', 'ROC', 'ATR', 'MFI', 'Chaikin_Oscillator', 'Adj Close']]\n",
    "\n",
    "# Example usage:\n",
    "ratios = [2, 3, 4, 5, 6, 7, 8, 9, 10]  # List of ratios between out_of_sample and in_sample\n",
    "results_r = evaluate_model_performance(data, sp500_ratio, dfX, Model, ratios)\n",
    "# initiate a list to contain R2, RMSE values of each model\n",
    "R2_training_set_ratio = results_r['R2']\n",
    "RMSE_ratio = results_r['RMSE']\n",
    "\n",
    "# initiate a list to contain R2, RMSE values of each model\n",
    "R2_validation_set_ratio = results_r['R2_Val']\n",
    "RMSE_validation_set_ratio = results_r['RMSE_Val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots (Ratio between Out_Of_Sample and In_Sample Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot list2 against list1\n",
    "plt.plot(ratios, R2_training_set_ratio, marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Ratio between in-sample and out_of_sample - Train Data')\n",
    "plt.ylabel('R2 - Gradient Boosting')\n",
    "plt.title('R2 vs. Ratio Number')\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot R2 for validation set\n",
    "plt.plot(ratios, R2_validation_set_ratio, marker='o', linestyle='-', label='Validation Set')\n",
    "\n",
    "# Plot R2 for training set\n",
    "plt.plot(ratios, R2_training_set_ratio, marker='o', linestyle='-', label='Training Set')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Ratio between in-sample and out_of_sample - Train Data')\n",
    "plt.ylabel('R2 - Gradient Boosting')\n",
    "plt.title('R2 vs. Ratio Number')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot list2 against list1\n",
    "plt.plot(ratios, RMSE_ratio, marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Ratio between in-sample and out_of_sample - Train Data')\n",
    "plt.ylabel('RMSE - Gradient Boosting')\n",
    "plt.title('RMSE vs. Ratio Number')\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE for validation set\n",
    "plt.plot(ratios, RMSE_validation_set_ratio, marker='o', linestyle='-', label='Validation Set')\n",
    "\n",
    "# Plot RMSE for training set\n",
    "plt.plot(ratios, RMSE_ratio, marker='o', linestyle='-', label='Training Set')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Splits - Validation Data')\n",
    "plt.ylabel('RMSE - Gradient Boosting')\n",
    "plt.title('RMSE vs. Ratio Number')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data to perform optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ratio = 3\n",
    "best_splits_num = 50\n",
    "nan_window = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the un proccessed dataframe\n",
    "sp500_d = sp500_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "out_sample_size = len(sp500_d) // (best_ratio + best_splits_num)\n",
    "in_sample_size = best_ratio * out_sample_size\n",
    "\n",
    "sp500_d = truncate_before_wf(sp500_d, in_sample_size, out_sample_size)\n",
    "splits = walk_forward_validation(sp500_d, in_sample_size, out_sample_size)\n",
    "\n",
    "# Adjust the predected df index (should cut the first unpredected 1300)\n",
    "index_dropped = best_ratio * out_sample_size #first idicies that are participating in the insample bur not predicted\n",
    "index_predict = out_sample_size #number of out of samples in each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create features\n",
    "splits_f = apply_feature_creation_to_splits(splits, chosen_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search SVR Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lC      = [1, 10, 100]\n",
    "lKernel = ['poly', 'rbf','linear']\n",
    "lgamma      = ['scale', 'auto', 0.1, 0.01, 0.001]\n",
    "ldegree = [3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Data Frame\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Calculate the number of combinations.\n",
    "# 2. Create a nested loop to create the combinations between the parameters.\n",
    "# 3. Store the combinations as the columns of a data frame.\n",
    "\n",
    "# For Advanced Python users: Use iteration tools for create the cartesian product\n",
    "numComb = len(lKernel) * len(lC) * len(lgamma) * len(ldegree)\n",
    "dData   = {'kernel': [], 'C': [], 'gamma':[], 'degree':[]}\n",
    "\n",
    "for ii, kernel in enumerate(lKernel):\n",
    "    for jj, paramC in enumerate(lC):\n",
    "        for kk, gamma in enumerate(lgamma):\n",
    "            for cc, degree in enumerate(ldegree):\n",
    "                dData['kernel'].append(kernel)\n",
    "                dData['C'].append(paramC)\n",
    "                dData['gamma'].append(gamma)\n",
    "                dData['degree'].append(degree)\n",
    "#===============================================================#\n",
    "\n",
    "dfModelScore = pd.DataFrame(data = dData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels()\n",
    "\n",
    "# Initialize an empty list to store predictions\n",
    "vY = sp500_d['Adj Close'].values\n",
    "vY = vY[index_dropped:]\n",
    "for ii in range(numComb):\n",
    "    kernel    = dfModelScore.loc[ii, 'kernel']\n",
    "    paramC          = dfModelScore.loc[ii, 'C']\n",
    "    gamma          = dfModelScore.loc[ii, 'gamma']\n",
    "    degree          = dfModelScore.loc[ii, 'degree']\n",
    "\n",
    "\n",
    "    print(f'Processing model {ii + 1:03d} out of {numComb}')\n",
    "\n",
    "    Model = TimeSeriesModels(svr_kernel=kernel, C=paramC, gamma=gamma, degree=degree)\n",
    "    predictions = Model.svr_train(splits_f, 'Adj Close')\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    #the calculation for eaach model was performed on the last split of the walk forward\n",
    "    mae, mse, rmse, r2, mape = Model.evaluate(vY[-index_predict+nan_window:], \n",
    "                                              predictions[-index_predict+nan_window:])\n",
    "    \n",
    "    # Update the 'R2' column in dfModelScore with the calculated R2 score\n",
    "    dfModelScore.loc[ii, 'MAE'] = mae\n",
    "    dfModelScore.loc[ii, 'MSE'] = mse\n",
    "    dfModelScore.loc[ii, 'RMSE'] = rmse\n",
    "    dfModelScore.loc[ii, 'R2'] = r2\n",
    "    dfModelScore.loc[ii, 'MAPE'] = mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Best Model Score or SVR Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of MAE, MSE, RMSE, and MAPE for each model\n",
    "dfModelScore['MeanScore'] = dfModelScore[['MAE', 'RMSE', 'MAPE']].mean(axis=1)\n",
    "\n",
    "# Find the index of the model with the lowest mean score\n",
    "best_model_index = dfModelScore['MeanScore'].idxmin()\n",
    "\n",
    "# Find the index of the model with the higher r2\n",
    "best_model_index_r2 = dfModelScore['R2'].idxmax()\n",
    "\n",
    "# Get the parameters of the best model\n",
    "best_model_params = dfModelScore.loc[best_model_index, ['kernel', 'C', 'gamma', 'degree']]\n",
    "\n",
    "# Get the parameters of the best model\n",
    "best_model_params_r2 = dfModelScore.loc[best_model_index_r2, ['kernel', 'C', 'gamma', 'degree']]\n",
    "\n",
    "\n",
    "# Print the parameters of the best model\n",
    "print(\"Best Model Parameters - lowest mean of (MAE, RMSE, MAPE):\")\n",
    "print(best_model_params)\n",
    "\n",
    "# Print the parameters of the best model\n",
    "print(\"\\n\\n Best Model Parameters - Higher R2:\")\n",
    "print(best_model_params_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the best SVR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels(svr_kernel='rbf', C=100, gamma='scale', degree=3)\n",
    "\n",
    "# Initialize an empty list to store predictions & adjust the df index (should cut the first unpredected 200)\n",
    "predictions = Model.svr_train(splits_f, 'Adj Close')\n",
    "\n",
    "sp500_d_includes_results = sp500_d.copy()\n",
    "sp500_d_includes_results = sp500_d_includes_results.iloc[index_dropped:, :]\n",
    "sp500_d_includes_results['Predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store predictions\n",
    "vY = sp500_d['Adj Close'].values\n",
    "vY = vY[index_dropped:]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae, mse, rmse, r2, mape = Model.evaluate(vY, predictions)\n",
    "\n",
    "# Update the 'R2' column in dfModelScore with the calculated R2 score\n",
    "dfModelScore.loc['MAE'] = mae\n",
    "dfModelScore.loc['MSE'] = mse\n",
    "dfModelScore.loc['RMSE'] = rmse\n",
    "dfModelScore.loc['R2'] = r2\n",
    "dfModelScore.loc['MAPE'] = mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dData   = {'K': []}\n",
    "\n",
    "#===============================================================#\n",
    "\n",
    "dfModelScore = pd.DataFrame(data = dData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels()\n",
    "\n",
    "# Initialize an empty list to store predictions\n",
    "vY = sp500_d['Adj Close'].values\n",
    "vY = vY[index_dropped:]\n",
    "for kk in range(10):\n",
    "    print(f'Processing model {kk + 1:03d} out of {10}')\n",
    "\n",
    "    Model = TimeSeriesModels(k=kk + 1)\n",
    "    predictions = Model.knn_train(splits_f, 'Adj Close')\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mae, mse, rmse, r2, mape = Model.evaluate(vY[-index_predict:], predictions[-index_predict:])\n",
    "    \n",
    "    # Update the 'R2' column in dfModelScore with the calculated R2 score\n",
    "    dfModelScore.loc[kk, 'k'] = kk + 1\n",
    "    dfModelScore.loc[kk, 'MAE'] = mae\n",
    "    dfModelScore.loc[kk, 'MSE'] = mse\n",
    "    dfModelScore.loc[kk, 'RMSE'] = rmse\n",
    "    dfModelScore.loc[kk, 'R2'] = r2\n",
    "    dfModelScore.loc[kk, 'MAPE'] = mape\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of MAE, MSE, RMSE, and MAPE for each model\n",
    "dfModelScore['MeanScore'] = dfModelScore[['MAE', 'RMSE', 'MAPE']].mean(axis=1)\n",
    "\n",
    "# Find the index of the model with the lowest mean score\n",
    "best_model_index = dfModelScore['MeanScore'].idxmin()\n",
    "\n",
    "# Find the index of the model with the higher r2\n",
    "best_model_index_r2 = dfModelScore['R2'].idxmax()\n",
    "\n",
    "# Get the parameters of the best model\n",
    "best_model_params = dfModelScore.loc[best_model_index, ['k']]\n",
    "\n",
    "# Get the parameters of the best model\n",
    "best_model_params_r2 = dfModelScore.loc[best_model_index_r2, ['k']]\n",
    "\n",
    "\n",
    "# Print the parameters of the best model\n",
    "print(f'Best Model Parameters - lowest mean of (MAE, RMSE, MAPE):\\n{best_model_params}')\n",
    "\n",
    "# Print the parameters of the best model\n",
    "print(f'\\nBest Model Parameters - Higher R2:\\n{best_model_params_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the best KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels(k=2)\n",
    "\n",
    "# Initialize an empty list to store predictions\n",
    "predictions = Model.knn_train(splits_f, 'Adj Close')\n",
    "\n",
    "sp500_d_includes_results = sp500_d.copy()\n",
    "sp500_d_includes_results = sp500_d_includes_results.iloc[index_dropped:, :]\n",
    "sp500_d_includes_results['Predictions'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegressor - no hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels()\n",
    "\n",
    "# Initialize an empty list to store predictions\n",
    "vY = sp500_d['Adj Close'].values\n",
    "vY = vY[index_dropped:]\n",
    "\n",
    "predictions = Model.lr_train(splits_f, 'Adj Close')\n",
    "nan_window = 19\n",
    "# Calculate evaluation metrics\n",
    "mae, mse, rmse, r2, mape = Model.evaluate(vY[-index_predict+nan_window:], predictions[-index_predict+nan_window:])\n",
    "\n",
    "# Update the 'R2' column in dfModelScore with the calculated R2 score\n",
    "dfModelScore.loc['MAE'] = mae\n",
    "dfModelScore.loc['MSE'] = mse\n",
    "dfModelScore.loc['RMSE'] = rmse\n",
    "dfModelScore.loc['R2'] = r2\n",
    "dfModelScore.loc['MAPE'] = mape\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LinearRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_d_includes_results = sp500_d.copy()\n",
    "sp500_d_includes_results = sp500_d_includes_results.iloc[index_dropped:, :]\n",
    "sp500_d_includes_results['Predictions'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_features = ['sqrt', 'log2', 4, 5, 6, 7]\n",
    "#criterion = ['squared_error', 'MAE']\n",
    "criterion = ['squared_error']\n",
    "n_estimators = [10, 100, 150, 200] #number of threes in the forest (100 default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Data Frame\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Calculate the number of combinations.\n",
    "# 2. Create a nested loop to create the combinations between the parameters.\n",
    "# 3. Store the combinations as the columns of a data frame.\n",
    "\n",
    "# For Advanced Python users: Use iteration tools for create the cartesian product\n",
    "numComb = len(m_features) * len(criterion) * len(n_estimators)\n",
    "dData   = {'max_features': [], 'criterion': [], 'n_estimators':[]}\n",
    "\n",
    "for ii, feature in enumerate(m_features):\n",
    "    for jj, cri in enumerate(criterion):\n",
    "        for kk, est in enumerate(n_estimators):\n",
    "            dData['max_features'].append(feature)\n",
    "            dData['criterion'].append(cri)\n",
    "            dData['n_estimators'].append(est)\n",
    "#===============================================================#\n",
    "\n",
    "dfModelScore = pd.DataFrame(data = dData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels()\n",
    "\n",
    "# Initialize an empty list to store predictions \n",
    "vY = sp500_d['Adj Close'].values\n",
    "vY = vY[index_dropped:]\n",
    "for ii in range(numComb):\n",
    "    rf_n_feature = dfModelScore.loc[ii, 'max_features']\n",
    "    rf_criterion = dfModelScore.loc[ii, 'criterion']\n",
    "    rf_n_est = dfModelScore.loc[ii, 'n_estimators']\n",
    "\n",
    "    print(f'Processing model {ii + 1:03d} out of {numComb}')\n",
    "    Model = TimeSeriesModels(rf_n_estimators=rf_n_est, rf_max_features=rf_n_feature ,rf_criterion = rf_criterion)\n",
    "    predictions = Model.rf_train(splits_f, 'Adj Close')\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mae, mse, rmse, r2, mape = Model.evaluate(vY, predictions)\n",
    "    \n",
    "    # Update the 'R2' column in dfModelScore with the calculated R2 score\n",
    "    dfModelScore.loc[ii, 'MAE'] = mae\n",
    "    dfModelScore.loc[ii, 'MSE'] = mse\n",
    "    dfModelScore.loc[ii, 'RMSE'] = rmse\n",
    "    dfModelScore.loc[ii, 'R2'] = r2\n",
    "    dfModelScore.loc[ii, 'MAPE'] = mape\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of MAE, MSE, RMSE, and MAPE for each model\n",
    "dfModelScore['MeanScore'] = dfModelScore[['MAE', 'RMSE', 'MAPE']].mean(axis=1)\n",
    "\n",
    "# Find the index of the model with the lowest mean score\n",
    "best_model_index = dfModelScore['MeanScore'].idxmin()\n",
    "\n",
    "# Find the index of the model with the higher r2\n",
    "best_model_index_r2 = dfModelScore['R2'].idxmax()\n",
    "\n",
    "# Get the parameters of the best model\n",
    "best_model_params = dfModelScore.loc[best_model_index, ['max_features', 'criterion', 'n_estimators']]\n",
    "\n",
    "# Get the parameters of the best model\n",
    "best_model_params_r2 = dfModelScore.loc[best_model_index_r2, ['max_features', 'criterion', 'n_estimators']]\n",
    "\n",
    "\n",
    "# Print the parameters of the best model\n",
    "print(\"Best Model Parameters - lowest mean of (MAE, RMSE, MAPE):\")\n",
    "print(best_model_params)\n",
    "\n",
    "# Print the parameters of the best model\n",
    "print(\"Best Model Parameters - Higher R2:\")\n",
    "print(best_model_params_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfModelScore.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the best Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels(rf_n_estimators=150, rf_max_features=7)\n",
    "\n",
    "# Initialize an empty list to store predictions \n",
    "predictions = Model.rf_train(splits, 'Adj Close')\n",
    "\n",
    "sp500_d_includes_results = sp500_d.copy()\n",
    "sp500_d_includes_results = sp500_d_includes_results.iloc[index_dropped:, :]\n",
    "sp500_d_includes_results['Predictions'] = predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_loss = ['squared_error', 'absolute_error', 'huber']\n",
    "L_criterion = ['friedman_mse', 'squared_error']\n",
    "L_n_estimators = [100, 150, 200] #number of threes in the forest (100 default)\n",
    "L_m_features = ['sqrt', 'log2', 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Data Frame\n",
    "\n",
    "#===========================Fill This===========================#\n",
    "# 1. Calculate the number of combinations.\n",
    "# 2. Create a nested loop to create the combinations between the parameters.\n",
    "# 3. Store the combinations as the columns of a data frame.\n",
    "\n",
    "# For Advanced Python users: Use iteration tools for create the cartesian product\n",
    "numComb = len(L_loss) * len(L_criterion) * len(L_n_estimators) *len(L_m_features)\n",
    "dData   = {'loss': [], 'criterion': [], 'n_estimators':[], 'm_features':[]}\n",
    "\n",
    "for ii, lss in enumerate(L_loss):\n",
    "    for jj, cri in enumerate(L_criterion):\n",
    "        for kk, est in enumerate(L_n_estimators):\n",
    "            for kk, feature in enumerate(L_m_features):\n",
    "                dData['loss'].append(lss)\n",
    "                dData['criterion'].append(cri)\n",
    "                dData['n_estimators'].append(est)\n",
    "                dData['m_features'].append(feature)\n",
    "#===============================================================#\n",
    "\n",
    "dfModelScore = pd.DataFrame(data = dData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels()\n",
    "\n",
    "# Initialize an empty list to store predictions\n",
    "vY = sp500_d['Adj Close'].values\n",
    "vY = vY[index_dropped:]\n",
    "for ii in range(numComb):\n",
    "    gbm_lo = dfModelScore.loc[ii, 'loss']\n",
    "    gbm_cri = dfModelScore.loc[ii, 'criterion']\n",
    "    gbm_n_est = dfModelScore.loc[ii, 'n_estimators']\n",
    "    gbm_feat = dfModelScore.loc[ii, 'm_features']\n",
    "\n",
    "    print(f'Processing model {ii + 1:03d} out of {numComb}')\n",
    "    Model = TimeSeriesModels(gbm_n_estimators=gbm_n_est, gbm_criterion=gbm_cri, gbm_loss=gbm_lo\n",
    "                                                   ,gbm_n_features=gbm_feat)\n",
    "    predictions = Model.gbm_train(splits_f, 'Adj Close')\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mae, mse, rmse, r2, mape = Model.evaluate(vY, predictions)\n",
    "    \n",
    "    # Update the 'R2' column in dfModelScore with the calculated R2 score\n",
    "    dfModelScore.loc[ii, 'MAE'] = mae\n",
    "    dfModelScore.loc[ii, 'MSE'] = mse\n",
    "    dfModelScore.loc[ii, 'RMSE'] = rmse\n",
    "    dfModelScore.loc[ii, 'R2'] = r2\n",
    "    dfModelScore.loc[ii, 'MAPE'] = mape\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of MAE, MSE, RMSE, and MAPE for each model\n",
    "dfModelScore['MeanScore'] = dfModelScore[['MAE', 'RMSE', 'MAPE']].mean(axis=1)\n",
    "\n",
    "# Find the index of the model with the lowest mean score\n",
    "best_model_index = dfModelScore['MeanScore'].idxmin()\n",
    "\n",
    "# Find the index of the model with the higher r2\n",
    "best_model_index_r2 = dfModelScore['R2'].idxmax()\n",
    "\n",
    "# Get the parameters of the best model\n",
    "best_model_params = dfModelScore.loc[best_model_index, ['loss', 'criterion', 'n_estimators', 'm_features']]\n",
    "\n",
    "# Get the parameters of the best model\n",
    "best_model_params_r2 = dfModelScore.loc[best_model_index_r2, ['loss', 'criterion', 'n_estimators', 'm_features']]\n",
    "\n",
    "\n",
    "# Print the parameters of the best model\n",
    "print(\"Best Model Parameters - lowest mean of (MAE, RMSE, MAPE):\")\n",
    "print(best_model_params)\n",
    "\n",
    "# Print the parameters of the best model\n",
    "print(\"Best Model Parameters - Higher R2:\")\n",
    "print(best_model_params_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = TimeSeriesModels(gbm_n_estimators=100, gbm_criterion='squared_error', \n",
    "                         gbm_loss='squared_error', gbm_n_features=7)\n",
    "predictions = Model.gbm_train(splits, 'Adj Close')\n",
    "\n",
    "sp500_d_includes_results = sp500_d.copy()\n",
    "sp500_d_includes_results = sp500_d_includes_results.iloc[index_dropped:, :]\n",
    "sp500_d_includes_results['Predictions'] = predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs. actual values\n",
    "plt.scatter(sp500_d_includes_results['Adj Close'], sp500_d_includes_results['Predictions'] )\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.show()\n",
    "\n",
    "mae = mean_absolute_error(sp500_d_includes_results['Adj Close'], sp500_d_includes_results['Predictions'] )\n",
    "mse = mean_squared_error(sp500_d_includes_results['Adj Close'], sp500_d_includes_results['Predictions'] )\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(sp500_d_includes_results['Adj Close'], sp500_d_includes_results['Predictions'] )\n",
    "mape = mean_absolute_percentage_error(sp500_d_includes_results['Adj Close'], sp500_d_includes_results['Predictions'] )\n",
    "\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame containing the data\n",
    "# Replace 'feature1' and 'feature2' with the names of the features you want to plot\n",
    "feature1 = 'Adj Close'\n",
    "feature2 = 'Predictions'\n",
    "\n",
    "# Create line plot\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=sp500_d_includes_results.index,  # Assuming the index represents x-axis values\n",
    "    y=sp500_d_includes_results[feature1],\n",
    "    mode='lines',\n",
    "    name=feature1\n",
    "))\n",
    "\n",
    "# Add another line plot for the second feature\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sp500_d_includes_results.index,  # Assuming the index represents x-axis values\n",
    "    y=sp500_d_includes_results[feature2],\n",
    "    mode='lines',\n",
    "    name=feature2\n",
    "))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Model - Adjusted Close Vs. Predictions on train dataset - WF 200,50 (100 splits)',\n",
    "    xaxis=dict(title='X Axis'),  # Customize x-axis label\n",
    "    yaxis=dict(title='Y Axis'),  # Customize y-axis label\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Predected values to returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze = sp500_d_includes_results.copy()\n",
    "#Calculate returns\n",
    "analyze = calculate_returns(analyze, 'Adj Close', 'Returns')\n",
    "analyze = calculate_returns(analyze, 'Predictions', 'Predicted Returns')\n",
    "\n",
    "#calculate buy and sell signals\n",
    "analyze = calculate_signal(analyze, 'Returns', 'Signal')\n",
    "analyze = calculate_signal(analyze, 'Predicted Returns', 'Predicted Signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the distribution of the returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_distribution(analyze, 'Predicted Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = 'Returns'\n",
    "feature2 = 'Predicted Returns'\n",
    "\n",
    "# Create line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line plot for feature1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=analyze.index,  # Assuming the index represents x-axis values\n",
    "    y=analyze[feature1],\n",
    "    mode='lines',\n",
    "    name=feature1\n",
    "))\n",
    "\n",
    "# Add line plot for feature2\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=analyze.index,  # Assuming the index represents x-axis values\n",
    "    y=analyze[feature2],\n",
    "    mode='lines',\n",
    "    name=feature2\n",
    "))\n",
    "\n",
    "# Calculate quartiles for feature1\n",
    "q1_feature1 = analyze[feature1].quantile(0.25)\n",
    "q3_feature1 = analyze[feature1].quantile(0.75)\n",
    "\n",
    "# Calculate quartiles for feature2\n",
    "q1_feature2 = analyze[feature2].quantile(0.25)\n",
    "q3_feature2 = analyze[feature2].quantile(0.75)\n",
    "\n",
    "# Add horizontal lines for quartiles for feature1\n",
    "fig.add_hline(y=q1_feature1, line_dash=\"dash\", line_color=\"green\", annotation_text=f'{feature1} Q1: {q1_feature1}', annotation_position=\"bottom right\")\n",
    "fig.add_hline(y=q3_feature1, line_dash=\"dash\", line_color=\"orange\", annotation_text=f'{feature1} Q3: {q3_feature1}', annotation_position=\"top right\")\n",
    "\n",
    "# Add horizontal lines for quartiles for feature2\n",
    "fig.add_hline(y=q1_feature2, line_dash=\"dash\", line_color=\"black\", annotation_text=f'{feature2} Q1: {q1_feature2}', annotation_position=\"bottom left\")\n",
    "fig.add_hline(y=q3_feature2, line_dash=\"dash\", line_color=\"white\", annotation_text=f'{feature2} Q3: {q3_feature2}', annotation_position=\"top left\")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Model - Predicted Returns Vs. Returns - WF 200,20',\n",
    "    xaxis=dict(title='Time Index'),  # Customize x-axis label\n",
    "    yaxis=dict(title='Returns'),  # Customize y-axis label\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a bench Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate bench mark buy and hold returns\n",
    "analyze = calculate_buy_and_hold_returns(analyze, 'Adj Close', 'Returns BH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpe Ratio / Information Ratio / Maximum Drowdown: returns vs predected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp_true = calculate_sharpe_ratio(analyze['Returns'])\n",
    "sharp_pred = calculate_sharpe_ratio(analyze['Predicted Returns'])\n",
    "sharp_BH = calculate_sharpe_ratio(analyze['Returns BH'])\n",
    "ir_true = calculate_ir(analyze['Returns'],  analyze['Returns BH'])\n",
    "ir_pred = calculate_ir(analyze['Predicted Returns'],  analyze['Returns BH'])\n",
    "ir_BH = calculate_ir(analyze['Returns BH'],  analyze['Returns BH'])\n",
    "mdd_true = calculate_mdd(analyze['Returns'])\n",
    "mdd_pred = calculate_mdd(analyze['Predicted Returns'])\n",
    "mdd_BH = calculate_mdd(analyze['Returns BH'])\n",
    "\n",
    "print(sharp_true, sharp_pred, sharp_BH, ir_true, ir_pred, ir_BH, mdd_true, mdd_pred, mdd_BH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy =calculate_accuracy(analyze['Signal'],analyze['Predicted Signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Accuracy is  {train_accuracy:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the validation set\n",
    "dfX = sp500_val.copy()\n",
    "dfX = dfX.loc[:, ['SMA','WMA', 'MACD', 'RSI', '%K_fast', '%D_fast', '%D_slow', 'Bollinger Diff',\n",
    "                    'WPR', 'OBV', 'ROC', 'ATR', 'MFI', 'Chaikin_Oscillator', 'Adj Close']]\n",
    "\n",
    "#drop the Adjusted Close feature\n",
    "feat_dfX = dfX.drop(columns='Adj Close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX['Predicted Adj Close'] = Model.svr_predict(feat_dfX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate returns\n",
    "dfX = calculate_returns(dfX, 'Adj Close', 'Returns')\n",
    "dfX = calculate_returns(dfX, 'Predicted Adj Close', 'Predicted Returns')\n",
    "\n",
    "#calculate buy and sell signals\n",
    "dfX = calculate_signal(dfX, 'Predicted Returns', 'Predicted Signal')\n",
    "dfX = calculate_signal(dfX, 'Returns', 'Signal')\n",
    "\n",
    "#calculate model accuracy\n",
    "validation_accuracy = calculate_accuracy(dfX['Signal'], dfX['Predicted Signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Validation Accuracy is {validation_accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the predected Adjucted Close Vs Adj Close\n",
    "feature1 = 'Adj Close'\n",
    "feature2 = 'Predicted Adj Close'\n",
    "\n",
    "# Create line plot\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=dfX.index,  # Assuming the index represents x-axis values\n",
    "    y=dfX[feature1],\n",
    "    mode='lines',\n",
    "    name=feature1\n",
    "))\n",
    "\n",
    "# Add another line plot for the second feature\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dfX.index,  # Assuming the index represents x-axis values\n",
    "    y=dfX[feature2],\n",
    "    mode='lines',\n",
    "    name=feature2\n",
    "))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Model - Adjusted Close Vs. Predictions',\n",
    "    xaxis=dict(title='X Axis'),  # Customize x-axis label\n",
    "    yaxis=dict(title='Y Axis'),  # Customize y-axis label\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show returns and quantiles\n",
    "feature1 = 'Returns'\n",
    "feature2 = 'Predicted Returns'\n",
    "\n",
    "# Create line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line plot for feature1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dfX.index,  # Assuming the index represents x-axis values\n",
    "    y=dfX[feature1],\n",
    "    mode='lines',\n",
    "    name=feature1\n",
    "))\n",
    "\n",
    "# Add line plot for feature2\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dfX.index,  # Assuming the index represents x-axis values\n",
    "    y=dfX[feature2],\n",
    "    mode='lines',\n",
    "    name=feature2\n",
    "))\n",
    "\n",
    "# Calculate quartiles for feature1\n",
    "q1_feature1 = dfX[feature1].quantile(0.25)\n",
    "q3_feature1 = dfX[feature1].quantile(0.75)\n",
    "\n",
    "# Calculate quartiles for feature2\n",
    "q1_feature2 = dfX[feature2].quantile(0.25)\n",
    "q3_feature2 = dfX[feature2].quantile(0.75)\n",
    "\n",
    "# Add horizontal lines for quartiles for feature1\n",
    "fig.add_hline(y=q1_feature1, line_dash=\"dash\", line_color=\"green\", annotation_text=f'{feature1} Q1: {q1_feature1}', annotation_position=\"bottom right\")\n",
    "fig.add_hline(y=q3_feature1, line_dash=\"dash\", line_color=\"orange\", annotation_text=f'{feature1} Q3: {q3_feature1}', annotation_position=\"top right\")\n",
    "\n",
    "# Add horizontal lines for quartiles for feature2\n",
    "fig.add_hline(y=q1_feature2, line_dash=\"dash\", line_color=\"black\", annotation_text=f'{feature2} Q1: {q1_feature2}', annotation_position=\"bottom left\")\n",
    "fig.add_hline(y=q3_feature2, line_dash=\"dash\", line_color=\"white\", annotation_text=f'{feature2} Q3: {q3_feature2}', annotation_position=\"top left\")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Model - Predicted Returns Vs. Returns - WF 200,20',\n",
    "    xaxis=dict(title='Time Index'),  # Customize x-axis label\n",
    "    yaxis=dict(title='Returns'),  # Customize y-axis label\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
